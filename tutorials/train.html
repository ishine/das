
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Train</title>
    
  <link rel="stylesheet" href="../_static/css/index.73d71520a4ca3b99cfee5594769eaaae.css">

    
  <link rel="stylesheet"
    href="../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      
  <link rel="stylesheet"
    href="../_static/vendor/open-sans_all/1.44.1/index.css">
  <link rel="stylesheet"
    href="../_static/vendor/lato_latin-ext/1.44.1/index.css">

    
    <link rel="stylesheet" href="../_static/sphinx-book-theme.40e2e510f6b7d1648584402491bb10fe.css" type="text/css" />
    <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-main.c949a650a448cc0ae9fd3441c0e17fb0.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-variables.06eb56fa6e07937060861dad626602ad.css" />
    
  <link rel="preload" as="script" href="../_static/js/index.3da636dd464baa7582d2.js">

    <script id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/language_data.js"></script>
    <script src="../_static/togglebutton.js"></script>
    <script src="../_static/clipboard.min.js"></script>
    <script src="../_static/copybutton.js"></script>
    <script >var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="../_static/sphinx-book-theme.d31b09fe5c1d09cb49b26a786de4a05d.js"></script>
    <script async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <script type="text/x-mathjax-config">MathJax.Hub.Config({"tex2jax": {"inlineMath": [["\\(", "\\)"]], "displayMath": [["\\[", "\\]"]], "processRefs": false, "processEnvironments": false}})</script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script src="https://unpkg.com/@jupyter-widgets/html-manager@^0.18.0/dist/embed-amd.js"></script>
    <script async="async" src="https://unpkg.com/thebelab@latest/lib/index.js"></script>
    <script >
        const thebe_selector = ".thebe"
        const thebe_selector_input = "pre"
        const thebe_selector_output = ".output"
    </script>
    <script async="async" src="../_static/sphinx-thebe.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Predict" href="predict.html" />
    <link rel="prev" title="Inspect dataset" href="inspect_dataset.html" />

    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="en" />



  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    

    <div class="container-xl">
      <div class="row">
          
<div class="col-12 col-md-3 bd-sidebar site-navigation show" id="site-navigation">
    
        <div class="navbar-brand-box">
<a class="navbar-brand text-wrap" href="../index.html">
  
  <img src="../_static/icon.png" class="logo" alt="logo">
  
  
</a>
</div><form class="bd-search d-flex align-items-center" action="../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form>
<nav class="bd-links" id="bd-docs-nav" aria-label="Main navigation">
    <ul class="nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="../intro.html">
   Welcome to DeepSS
  </a>
 </li>
</ul>
<ul class="current nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="../install.html">
   Install
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../quick_start.html">
   Quick start tutorial
  </a>
 </li>
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="../tutorials_gui/tutorials_gui.html">
   GUI documentation
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="../tutorials_gui/load.html">
     Load and view data
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../tutorials_gui/annotate.html">
     Annotate song
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../tutorials_gui/train.html">
     Train
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../tutorials_gui/predict.html">
     Predict
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
 <li class="toctree-l1 current active collapsible-parent">
  <a class="reference internal" href="tutorials.html">
   Programming documentation
  </a>
  <ul class="current collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="convert.html">
     Convert your own annotations and audio data
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="make_ds_notebook.html">
     Make a dataset from custom data formats
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="inspect_dataset.html">
     Inspect dataset
    </a>
   </li>
   <li class="toctree-l2 current active">
    <a class="current reference internal" href="#">
     Train
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="predict.html">
     Predict
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="colab.html">
     Training and inference with colab
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="label_segments.html">
     Generate segment labels
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="evaluate_fly.html">
     Evaluate a sine and pulse network
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="evaluate_bird.html">
     Evaluate a bird song network
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="realtime.html">
     Annotate audio in realtime
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="../unsupervised/unsupervised.html">
   Unsupervised classification
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="../unsupervised/flies.html">
     Courtship song of flies
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../unsupervised/mice.html">
     Ultrasonic vocalizations from mice
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../unsupervised/birds.html">
     Song of Bengalese finches
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="../technical/technical.html">
   Technical details
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="../technical/data_formats.html">
     Data formats
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../technical/cli.html">
     Command line interfaces
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../credits.html">
   Acknowledgements
  </a>
 </li>
</ul>

</nav> <!-- To handle the deprecated key -->

<div class="navbar_extra_footer">
  Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
</div>

</div>


          


          
<main class="col py-md-3 pl-md-4 bd-content overflow-auto" role="main">
    
    <div class="row topbar fixed-top container-xl">
    <div class="col-12 col-md-3 bd-topbar-whitespace site-navigation show">
    </div>
    <div class="col pl-2 topbar-main">
        
        <button id="navbar-toggler" class="navbar-toggler ml-0" type="button" data-toggle="collapse"
            data-toggle="tooltip" data-placement="bottom" data-target=".site-navigation" aria-controls="navbar-menu"
            aria-expanded="true" aria-label="Toggle navigation" aria-controls="site-navigation"
            title="Toggle navigation" data-toggle="tooltip" data-placement="left">
            <i class="fas fa-bars"></i>
            <i class="fas fa-arrow-left"></i>
            <i class="fas fa-arrow-up"></i>
        </button>
        
        
<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn" aria-label="Download this page"><i
            class="fas fa-download"></i></button>

    <div class="dropdown-buttons">
        <!-- ipynb file if we had a myst markdown file -->
        
        <!-- Download raw file -->
        <a class="dropdown-buttons" href="../_sources/tutorials/train.ipynb"><button type="button"
                class="btn btn-secondary topbarbtn" title="Download source file" data-toggle="tooltip"
                data-placement="left">.ipynb</button></a>
        <!-- Download PDF via print -->
        <button type="button" id="download-print" class="btn btn-secondary topbarbtn" title="Print to PDF"
            onClick="window.print()" data-toggle="tooltip" data-placement="left">.pdf</button>
    </div>
</div>

        <!-- Source interaction buttons -->


        <!-- Full screen (wrap in <a> to have style consistency -->
        <a class="full-screen-button"><button type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip"
                data-placement="bottom" onclick="toggleFullScreen()" aria-label="Fullscreen mode"
                title="Fullscreen mode"><i
                    class="fas fa-expand"></i></button></a>

        <!-- Launch buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Launch interactive content"><i class="fas fa-rocket"></i></button>
    <div class="dropdown-buttons">
        
        <a class="binder-button" href="https://mybinder.org/v2/gh/executablebooks/jupyter-book/master?urlpath=tree/tutorials/train.ipynb"><button type="button"
                class="btn btn-secondary topbarbtn" title="Launch Binder" data-toggle="tooltip"
                data-placement="left"><img class="binder-button-logo"
                    src="../_static/images/logo_binder.svg"
                    alt="Interact on binder">Binder</button></a>
        
        
        
        
    </div>
</div>

    </div>

    <!-- Table of contents -->
    <div class="d-none d-md-block col-md-2 bd-toc show">
        
        <div class="tocsection onthispage pt-5 pb-3">
            <i class="fas fa-list"></i> Contents
        </div>
        <nav id="bd-toc-nav">
            <ul class="nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#training-using-python">
   Training using python
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#training-using-command-line-scripts">
   Training using command-line scripts
  </a>
 </li>
</ul>

        </nav>
        
    </div>
</div>
    <div id="main-content" class="row">
        <div class="col-12 col-md-9 pl-md-3 pr-md-0">
        
              <div>
                
  <div class="section" id="train">
<h1>Train<a class="headerlink" href="#train" title="Permalink to this headline">¶</a></h1>
<p>The network can be trained using three interfaces:</p>
<ul class="simple">
<li><p>python, via <code class="docutils literal notranslate"><span class="pre">dss.train.train</span></code></p></li>
<li><p>the command-line interface <code class="docutils literal notranslate"><span class="pre">dss</span> <span class="pre">train</span></code>.</p></li>
<li><p>the GUI - see the <a class="reference internal" href="../tutorials_gui/train.html"><span class="doc std std-doc">GUI tutorial</span></a></p></li>
</ul>
<p>Training will:</p>
<ul class="simple">
<li><p>load train/val/test data form a dataset</p></li>
<li><p>initialize the network</p></li>
<li><p>save all parameters for reproducibility</p></li>
<li><p>train the network and save the best network to disk</p></li>
<li><p>run inference and evaluate the network using the test data.</p></li>
</ul>
<p>The names of files created during training start with an optional prefix and the time stamp of the start time of training, as in <code class="docutils literal notranslate"><span class="pre">my-awesome-prefix_20192310_091032</span></code>. Typically, three files are created:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">*_params.yaml</span></code> - training parameters etc.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">*_model.h5</span></code> -  model architecture and weights</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">*_results.h5</span></code> - predictions and evaluation results for the test set (only created if the training dataset contains a test set)</p></li>
</ul>
<div class="section" id="training-using-python">
<h2>Training using python<a class="headerlink" href="#training-using-python" title="Permalink to this headline">¶</a></h2>
<p>Training is done using the <code class="docutils literal notranslate"><span class="pre">train</span></code> function in the <code class="docutils literal notranslate"><span class="pre">dss.train</span></code> module:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">dss.train</span>
<span class="n">help</span><span class="p">(</span><span class="n">dss</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">train</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Help on function train in module dss.train:

train(*, data_dir: str, y_suffix: str = &#39;&#39;, save_dir: str = &#39;./&#39;, save_prefix: str = None, model_name: str = &#39;tcn&#39;, nb_filters: int = 16, kernel_size: int = 16, nb_conv: int = 3, use_separable: List[bool] = False, nb_hist: int = 1024, ignore_boundaries: bool = True, batch_norm: bool = True, nb_pre_conv: int = 0, pre_kernel_size: int = 3, pre_nb_filters: int = 16, pre_nb_conv: int = 2, verbose: int = 2, batch_size: int = 32, nb_epoch: int = 400, learning_rate: float = None, reduce_lr: bool = False, reduce_lr_patience: int = 5, fraction_data: float = None, seed: int = None, batch_level_subsampling: bool = False, tensorboard: bool = False, log_messages: bool = False, nb_stacks: int = 2, with_y_hist: bool = True, x_suffix: str = &#39;&#39;)
    Train a DeepSS network.
    
    Args:
        data_dir (str): Path to the directory or file with the dataset for training.
                        Accepts npy-dirs (recommended), h5 files or zarr files.
                        See documentation for how the dataset should be organized.
        y_suffix (str): Select training target by suffix.
                        Song-type specific targets can be created with a training dataset,
                        Defaults to &#39;&#39; (will use the standard target &#39;y&#39;)
        save_dir (str): Directory to save training outputs.
                        The path of output files will constructed from the SAVE_DIR, an optional prefix, and the time stamp of the start of training.
                        Defaults to current directory (&#39;./&#39;).
        save_prefix (str): Prepend to timestamp.
                           Name of files created will be SAVE_DIR/SAVE_PREFIX + &quot;_&quot; + TIMESTAMP
                           or SAVE_DIR/ TIMESTAMP if SAVE_PREFIX is empty.
                           Defaults to &#39;&#39; (empty).
        model_name (str): Network architecture to use.
                          Use &quot;tcn&quot; (TCN) or &quot;tcn_stft&quot; (TCN with STFT frontend).
                          See dss.models for a description of all models.
                          Defaults to &#39;tcn&#39;.
        nb_filters (int): Number of filters per layer.
                          Defaults to 16.
        kernel_size (int): Duration of the filters (=kernels) in samples.
                           Defaults to 16.
        nb_conv (int): Number of TCN blocks in the network.
                       Defaults to 3.
        use_separable (List[bool]): Specify which TCN blocks should use separable convolutions.
                                    Provide as a space-separated sequence of &quot;False&quot; or &quot;True.
                                    For instance: &quot;True False False&quot; will set the first block in a
                                    three-block (as given by nb_conv) network to use separable convolutions.
                                    Defaults to False (no block uses separable convolution).
        nb_hist (int): Number of samples processed at once by the network (a.k.a chunk size).
                       Defaults to 1024.
        ignore_boundaries (bool): Minimize edge effects by discarding predictions at the edges of chunks.
                                  Defaults to True.
        batch_norm (bool): Batch normalize.
                           Defaults to True.
        nb_pre_conv (int): Adds downsampling frontend.
                           TCN: adds a frontend of N conv blocks (conv-relu-batchnorm-maxpool2) to the TCN - useful for reducing the sampling rate for USV.
                           TCN_STFT: stft
                           Defaults to 0 (no frontend).
        pre_nb_filters (int): [description]. Defaults to 16.
        pre_kernel_size (int): [description]. Defaults to 3.
        pre_nb_conv (int): [description]. Defaults to 3.
        verbose (int): Verbosity of training output (0 - no output(?), 1 - progress bar, 2 - one line per epoch).
                       Defaults to 2.
        batch_size (int): Batch size
                          Defaults to 32.
        nb_epoch (int): Maximal number of training epochs.
                        Training will stop early if validation loss did not decrease in the last 20 epochs.
                        Defaults to 400.
        learning_rate (float): Learning rate of the model. Defaults should work in most cases.
                               Values typically range between 0.1 and 0.00001.
                               If None, uses per model defaults: &quot;tcn&quot; 0.0001, &quot;tcn_stft&quot; 0.0005).
                               Defaults to None.
        reduce_lr (bool): Reduce learning rate on plateau.
                          Defaults to False.
        reduce_lr_patience (int): Number of epochs w/o a reduction in validation loss after which to trigger a reduction in learning rate.
                                  Defaults to 5.
        fraction_data (float): Fraction of training and validation to use for training.
                               Defaults to 1.0.
        seed (int): Random seed to reproducible select fractions of the data.
                    Defaults to None (no seed).
        batch_level_subsampling (bool): Select fraction of data for training from random subset of shuffled batches.
                                        If False, select a continuous chunk of the recording.
                                        Defaults to False.
        tensorboard (bool): Write tensorboard logs to save_dir.
                            Defaults to False.
        log_messages (bool): Sets logging level to INFO.
                             Defaults to False (will follow existing settings).
        nb_stacks (int): Unused if model name is &quot;tcn&quot; or &quot;tcn_stft&quot;. Defaults to 2.
        with_y_hist (bool): Unused if model name is &quot;tcn&quot; or &quot;tcn_stft&quot;. Defaults to True.
        x_suffix (str): Select specific training data based on suffix (e.g. x_suffix).
                        Defaults to &#39;&#39; (will use the standard data &#39;x&#39;)
</pre></div>
</div>
</div>
</div>
<p>The output of the <code class="docutils literal notranslate"><span class="pre">train</span></code> function is fairly verbose, to help with troubleshooting:</p>
<ul class="simple">
<li><p>run time parameters</p></li>
<li><p>information on the size of the training and validation data</p></li>
<li><p>network architecture</p></li>
<li><p>training progress (training and validation loss)</p></li>
<li><p>after training, a classification report for the test data (if test data exist in the dataset)</p></li>
</ul>
<p>To demonstrate the outputs of <code class="docutils literal notranslate"><span class="pre">train</span></code>, the following trains a small network on a small dataset to annotate pulse and sine song from <em>Drosophila melanogater</em>. Expected performance (f1-score) is about 75%.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">dss</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">train</span><span class="p">(</span><span class="n">model_name</span><span class="o">=</span><span class="s1">&#39;tcn&#39;</span><span class="p">,</span>  <span class="c1"># see `dss.models` for valid model_names</span>
                <span class="n">data_dir</span><span class="o">=</span><span class="s1">&#39;tutorial_dataset.npy&#39;</span><span class="p">,</span> 
                <span class="n">save_dir</span><span class="o">=</span><span class="s1">&#39;res&#39;</span><span class="p">,</span>
                <span class="n">nb_hist</span><span class="o">=</span><span class="mi">256</span><span class="p">,</span>
                <span class="n">kernel_size</span><span class="o">=</span><span class="mi">16</span><span class="p">,</span>
                <span class="n">nb_filters</span><span class="o">=</span><span class="mi">16</span><span class="p">,</span>
                <span class="n">ignore_boundaries</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                <span class="n">verbose</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
                <span class="n">nb_epoch</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span>
                <span class="n">log_messages</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
</div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">INFO</span><span class="p">:</span><span class="n">root</span><span class="p">:</span><span class="n">loading</span> <span class="n">data</span>
<span class="n">INFO</span><span class="p">:</span><span class="n">root</span><span class="p">:</span><span class="n">Parameters</span><span class="p">:</span>
<span class="n">INFO</span><span class="p">:</span><span class="n">root</span><span class="p">:{</span><span class="s1">&#39;data_dir&#39;</span><span class="p">:</span> <span class="s1">&#39;tutorial_dataset.npy&#39;</span><span class="p">,</span> <span class="s1">&#39;y_suffix&#39;</span><span class="p">:</span> <span class="s1">&#39;&#39;</span><span class="p">,</span> <span class="s1">&#39;save_dir&#39;</span><span class="p">:</span> <span class="s1">&#39;res&#39;</span><span class="p">,</span> <span class="s1">&#39;save_prefix&#39;</span><span class="p">:</span> <span class="s1">&#39;&#39;</span><span class="p">,</span> <span class="s1">&#39;model_name&#39;</span><span class="p">:</span> <span class="s1">&#39;tcn&#39;</span><span class="p">,</span> <span class="s1">&#39;nb_filters&#39;</span><span class="p">:</span> <span class="mi">16</span><span class="p">,</span> <span class="s1">&#39;kernel_size&#39;</span><span class="p">:</span> <span class="mi">16</span><span class="p">,</span> <span class="s1">&#39;nb_conv&#39;</span><span class="p">:</span> <span class="mi">3</span><span class="p">,</span> <span class="s1">&#39;use_separable&#39;</span><span class="p">:</span> <span class="kc">False</span><span class="p">,</span> <span class="s1">&#39;nb_hist&#39;</span><span class="p">:</span> <span class="mi">256</span><span class="p">,</span> <span class="s1">&#39;ignore_boundaries&#39;</span><span class="p">:</span> <span class="kc">True</span><span class="p">,</span> <span class="s1">&#39;batch_norm&#39;</span><span class="p">:</span> <span class="kc">True</span><span class="p">,</span> <span class="s1">&#39;nb_pre_conv&#39;</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span> <span class="s1">&#39;pre_kernel_size&#39;</span><span class="p">:</span> <span class="mi">3</span><span class="p">,</span> <span class="s1">&#39;pre_nb_filters&#39;</span><span class="p">:</span> <span class="mi">16</span><span class="p">,</span> <span class="s1">&#39;pre_nb_conv&#39;</span><span class="p">:</span> <span class="mi">2</span><span class="p">,</span> <span class="s1">&#39;verbose&#39;</span><span class="p">:</span> <span class="mi">1</span><span class="p">,</span> <span class="s1">&#39;batch_size&#39;</span><span class="p">:</span> <span class="mi">32</span><span class="p">,</span> <span class="s1">&#39;nb_epoch&#39;</span><span class="p">:</span> <span class="mi">4</span><span class="p">,</span> <span class="s1">&#39;reduce_lr&#39;</span><span class="p">:</span> <span class="kc">False</span><span class="p">,</span> <span class="s1">&#39;reduce_lr_patience&#39;</span><span class="p">:</span> <span class="mi">5</span><span class="p">,</span> <span class="s1">&#39;fraction_data&#39;</span><span class="p">:</span> <span class="kc">None</span><span class="p">,</span> <span class="s1">&#39;seed&#39;</span><span class="p">:</span> <span class="kc">None</span><span class="p">,</span> <span class="s1">&#39;batch_level_subsampling&#39;</span><span class="p">:</span> <span class="kc">False</span><span class="p">,</span> <span class="s1">&#39;tensorboard&#39;</span><span class="p">:</span> <span class="kc">False</span><span class="p">,</span> <span class="s1">&#39;log_messages&#39;</span><span class="p">:</span> <span class="kc">True</span><span class="p">,</span> <span class="s1">&#39;nb_stacks&#39;</span><span class="p">:</span> <span class="mi">2</span><span class="p">,</span> <span class="s1">&#39;with_y_hist&#39;</span><span class="p">:</span> <span class="kc">True</span><span class="p">,</span> <span class="s1">&#39;x_suffix&#39;</span><span class="p">:</span> <span class="s1">&#39;&#39;</span><span class="p">,</span> <span class="s1">&#39;sample_weight_mode&#39;</span><span class="p">:</span> <span class="s1">&#39;temporal&#39;</span><span class="p">,</span> <span class="s1">&#39;data_padding&#39;</span><span class="p">:</span> <span class="mi">48</span><span class="p">,</span> <span class="s1">&#39;return_sequences&#39;</span><span class="p">:</span> <span class="kc">True</span><span class="p">,</span> <span class="s1">&#39;stride&#39;</span><span class="p">:</span> <span class="mi">160</span><span class="p">,</span> <span class="s1">&#39;y_offset&#39;</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span> <span class="s1">&#39;output_stride&#39;</span><span class="p">:</span> <span class="mi">1</span><span class="p">,</span> <span class="s1">&#39;class_names&#39;</span><span class="p">:</span> <span class="p">[</span><span class="s1">&#39;noise&#39;</span><span class="p">,</span> <span class="s1">&#39;pulse&#39;</span><span class="p">,</span> <span class="s1">&#39;sine&#39;</span><span class="p">],</span> <span class="s1">&#39;class_names_pulse&#39;</span><span class="p">:</span> <span class="p">[</span><span class="s1">&#39;noise&#39;</span><span class="p">,</span> <span class="s1">&#39;pulse&#39;</span><span class="p">],</span> <span class="s1">&#39;class_names_sine&#39;</span><span class="p">:</span> <span class="p">[</span><span class="s1">&#39;noise&#39;</span><span class="p">,</span> <span class="s1">&#39;sine&#39;</span><span class="p">],</span> <span class="s1">&#39;class_types&#39;</span><span class="p">:</span> <span class="p">[</span><span class="s1">&#39;segment&#39;</span><span class="p">,</span> <span class="s1">&#39;event&#39;</span><span class="p">,</span> <span class="s1">&#39;segment&#39;</span><span class="p">],</span> <span class="s1">&#39;class_types_pulse&#39;</span><span class="p">:</span> <span class="p">[</span><span class="s1">&#39;segment&#39;</span><span class="p">,</span> <span class="s1">&#39;event&#39;</span><span class="p">],</span> <span class="s1">&#39;class_types_sine&#39;</span><span class="p">:</span> <span class="p">[</span><span class="s1">&#39;segment&#39;</span><span class="p">,</span> <span class="s1">&#39;segment&#39;</span><span class="p">],</span> <span class="s1">&#39;filename_endsample_test&#39;</span><span class="p">:</span> <span class="p">[],</span> <span class="s1">&#39;filename_endsample_train&#39;</span><span class="p">:</span> <span class="p">[],</span> <span class="s1">&#39;filename_endsample_val&#39;</span><span class="p">:</span> <span class="p">[],</span> <span class="s1">&#39;filename_startsample_test&#39;</span><span class="p">:</span> <span class="p">[],</span> <span class="s1">&#39;filename_startsample_train&#39;</span><span class="p">:</span> <span class="p">[],</span> <span class="s1">&#39;filename_startsample_val&#39;</span><span class="p">:</span> <span class="p">[],</span> <span class="s1">&#39;filename_train&#39;</span><span class="p">:</span> <span class="p">[],</span> <span class="s1">&#39;filename_val&#39;</span><span class="p">:</span> <span class="p">[],</span> <span class="s1">&#39;samplerate_x_Hz&#39;</span><span class="p">:</span> <span class="mi">10000</span><span class="p">,</span> <span class="s1">&#39;samplerate_y_Hz&#39;</span><span class="p">:</span> <span class="mi">10000</span><span class="p">,</span> <span class="s1">&#39;filename_test&#39;</span><span class="p">:</span> <span class="p">[],</span> <span class="s1">&#39;nb_freq&#39;</span><span class="p">:</span> <span class="mi">1</span><span class="p">,</span> <span class="s1">&#39;nb_channels&#39;</span><span class="p">:</span> <span class="mi">1</span><span class="p">,</span> <span class="s1">&#39;nb_classes&#39;</span><span class="p">:</span> <span class="mi">3</span><span class="p">,</span> <span class="s1">&#39;first_sample_train&#39;</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span> <span class="s1">&#39;last_sample_train&#39;</span><span class="p">:</span> <span class="kc">None</span><span class="p">,</span> <span class="s1">&#39;first_sample_val&#39;</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span> <span class="s1">&#39;last_sample_val&#39;</span><span class="p">:</span> <span class="kc">None</span><span class="p">}</span>
<span class="n">INFO</span><span class="p">:</span><span class="n">root</span><span class="p">:</span><span class="n">preparing</span> <span class="n">data</span>
<span class="n">INFO</span><span class="p">:</span><span class="n">root</span><span class="p">:</span><span class="n">Training</span> <span class="n">data</span><span class="p">:</span>
<span class="n">INFO</span><span class="p">:</span><span class="n">root</span><span class="p">:</span><span class="n">AudioSequence</span> <span class="k">with</span> <span class="mi">3992</span> <span class="n">batches</span> <span class="n">each</span> <span class="k">with</span> <span class="mi">32</span> <span class="n">items</span><span class="o">.</span>
   <span class="n">Total</span> <span class="n">of</span> <span class="mi">20440005</span> <span class="n">samples</span> <span class="k">with</span>
   <span class="n">each</span> <span class="n">x</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,)</span> <span class="ow">and</span>
   <span class="n">each</span> <span class="n">y</span><span class="o">=</span><span class="p">(</span><span class="mi">3</span><span class="p">,)</span>
<span class="n">INFO</span><span class="p">:</span><span class="n">root</span><span class="p">:</span><span class="n">Validation</span> <span class="n">data</span><span class="p">:</span>
<span class="n">INFO</span><span class="p">:</span><span class="n">root</span><span class="p">:</span><span class="n">AudioSequence</span> <span class="k">with</span> <span class="mi">812</span> <span class="n">batches</span> <span class="n">each</span> <span class="k">with</span> <span class="mi">32</span> <span class="n">items</span><span class="o">.</span>
   <span class="n">Total</span> <span class="n">of</span> <span class="mi">4160001</span> <span class="n">samples</span> <span class="k">with</span>
   <span class="n">each</span> <span class="n">x</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,)</span> <span class="ow">and</span>
   <span class="n">each</span> <span class="n">y</span><span class="o">=</span><span class="p">(</span><span class="mi">3</span><span class="p">,)</span>
<span class="n">INFO</span><span class="p">:</span><span class="n">root</span><span class="p">:</span><span class="n">building</span> <span class="n">network</span>
<span class="n">WARNING</span><span class="p">:</span><span class="n">tensorflow</span><span class="p">:</span><span class="n">From</span> <span class="o">/</span><span class="n">Users</span><span class="o">/</span><span class="n">clemens10</span><span class="o">/</span><span class="n">miniconda3</span><span class="o">/</span><span class="n">lib</span><span class="o">/</span><span class="n">python3</span><span class="o">.</span><span class="mi">7</span><span class="o">/</span><span class="n">site</span><span class="o">-</span><span class="n">packages</span><span class="o">/</span><span class="n">tensorflow_core</span><span class="o">/</span><span class="n">python</span><span class="o">/</span><span class="n">ops</span><span class="o">/</span><span class="n">resource_variable_ops</span><span class="o">.</span><span class="n">py</span><span class="p">:</span><span class="mi">1635</span><span class="p">:</span> <span class="n">calling</span> <span class="n">BaseResourceVariable</span><span class="o">.</span><span class="fm">__init__</span> <span class="p">(</span><span class="kn">from</span> <span class="nn">tensorflow.python.ops.resource_variable_ops</span><span class="p">)</span> <span class="k">with</span> <span class="n">constraint</span> <span class="ow">is</span> <span class="n">deprecated</span> <span class="ow">and</span> <span class="n">will</span> <span class="n">be</span> <span class="n">removed</span> <span class="ow">in</span> <span class="n">a</span> <span class="n">future</span> <span class="n">version</span><span class="o">.</span>
<span class="n">Instructions</span> <span class="k">for</span> <span class="n">updating</span><span class="p">:</span>
<span class="n">If</span> <span class="n">using</span> <span class="n">Keras</span> <span class="k">pass</span> <span class="o">*</span><span class="n">_constraint</span> <span class="n">arguments</span> <span class="n">to</span> <span class="n">layers</span><span class="o">.</span>
<span class="n">WARNING</span><span class="p">:</span><span class="n">tensorflow</span><span class="p">:</span><span class="n">From</span> <span class="o">/</span><span class="n">Users</span><span class="o">/</span><span class="n">clemens10</span><span class="o">/</span><span class="n">miniconda3</span><span class="o">/</span><span class="n">lib</span><span class="o">/</span><span class="n">python3</span><span class="o">.</span><span class="mi">7</span><span class="o">/</span><span class="n">site</span><span class="o">-</span><span class="n">packages</span><span class="o">/</span><span class="n">tensorflow_core</span><span class="o">/</span><span class="n">python</span><span class="o">/</span><span class="n">ops</span><span class="o">/</span><span class="n">resource_variable_ops</span><span class="o">.</span><span class="n">py</span><span class="p">:</span><span class="mi">1635</span><span class="p">:</span> <span class="n">calling</span> <span class="n">BaseResourceVariable</span><span class="o">.</span><span class="fm">__init__</span> <span class="p">(</span><span class="kn">from</span> <span class="nn">tensorflow.python.ops.resource_variable_ops</span><span class="p">)</span> <span class="k">with</span> <span class="n">constraint</span> <span class="ow">is</span> <span class="n">deprecated</span> <span class="ow">and</span> <span class="n">will</span> <span class="n">be</span> <span class="n">removed</span> <span class="ow">in</span> <span class="n">a</span> <span class="n">future</span> <span class="n">version</span><span class="o">.</span>
<span class="n">Instructions</span> <span class="k">for</span> <span class="n">updating</span><span class="p">:</span>
<span class="n">If</span> <span class="n">using</span> <span class="n">Keras</span> <span class="k">pass</span> <span class="o">*</span><span class="n">_constraint</span> <span class="n">arguments</span> <span class="n">to</span> <span class="n">layers</span><span class="o">.</span>
<span class="n">INFO</span><span class="p">:</span><span class="n">root</span><span class="p">:</span><span class="kc">None</span>
<span class="n">INFO</span><span class="p">:</span><span class="n">root</span><span class="p">:</span><span class="n">start</span> <span class="n">training</span>
<span class="n">Model</span><span class="p">:</span> <span class="s2">&quot;TCN&quot;</span>
<span class="n">__________________________________________________________________________________________________</span>
<span class="n">Layer</span> <span class="p">(</span><span class="nb">type</span><span class="p">)</span>                    <span class="n">Output</span> <span class="n">Shape</span>         <span class="n">Param</span> <span class="c1">#     Connected to                     </span>
<span class="o">==================================================================================================</span>
<span class="n">input_1</span> <span class="p">(</span><span class="n">InputLayer</span><span class="p">)</span>            <span class="p">[(</span><span class="kc">None</span><span class="p">,</span> <span class="mi">256</span><span class="p">,</span> <span class="mi">1</span><span class="p">)]</span>     <span class="mi">0</span>                                            
<span class="n">__________________________________________________________________________________________________</span>
<span class="n">conv1d</span> <span class="p">(</span><span class="n">Conv1D</span><span class="p">)</span>                 <span class="p">(</span><span class="kc">None</span><span class="p">,</span> <span class="mi">256</span><span class="p">,</span> <span class="mi">16</span><span class="p">)</span>      <span class="mi">32</span>          <span class="n">input_1</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span>                    
<span class="n">__________________________________________________________________________________________________</span>
<span class="n">conv1d_1</span> <span class="p">(</span><span class="n">Conv1D</span><span class="p">)</span>               <span class="p">(</span><span class="kc">None</span><span class="p">,</span> <span class="mi">256</span><span class="p">,</span> <span class="mi">16</span><span class="p">)</span>      <span class="mi">4112</span>        <span class="n">conv1d</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span>                     
<span class="n">__________________________________________________________________________________________________</span>
<span class="n">activation</span> <span class="p">(</span><span class="n">Activation</span><span class="p">)</span>         <span class="p">(</span><span class="kc">None</span><span class="p">,</span> <span class="mi">256</span><span class="p">,</span> <span class="mi">16</span><span class="p">)</span>      <span class="mi">0</span>           <span class="n">conv1d_1</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span>                   
<span class="n">__________________________________________________________________________________________________</span>
<span class="k">lambda</span> <span class="p">(</span><span class="n">Lambda</span><span class="p">)</span>                 <span class="p">(</span><span class="kc">None</span><span class="p">,</span> <span class="mi">256</span><span class="p">,</span> <span class="mi">16</span><span class="p">)</span>      <span class="mi">0</span>           <span class="n">activation</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span>                 
<span class="n">__________________________________________________________________________________________________</span>
<span class="n">spatial_dropout1d</span> <span class="p">(</span><span class="n">SpatialDropo</span> <span class="p">(</span><span class="kc">None</span><span class="p">,</span> <span class="mi">256</span><span class="p">,</span> <span class="mi">16</span><span class="p">)</span>      <span class="mi">0</span>           <span class="k">lambda</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span>                     
<span class="n">__________________________________________________________________________________________________</span>
<span class="n">conv1d_2</span> <span class="p">(</span><span class="n">Conv1D</span><span class="p">)</span>               <span class="p">(</span><span class="kc">None</span><span class="p">,</span> <span class="mi">256</span><span class="p">,</span> <span class="mi">16</span><span class="p">)</span>      <span class="mi">272</span>         <span class="n">spatial_dropout1d</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span>          
<span class="n">__________________________________________________________________________________________________</span>
<span class="n">add</span> <span class="p">(</span><span class="n">Add</span><span class="p">)</span>                       <span class="p">(</span><span class="kc">None</span><span class="p">,</span> <span class="mi">256</span><span class="p">,</span> <span class="mi">16</span><span class="p">)</span>      <span class="mi">0</span>           <span class="n">conv1d</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span>                     
                                                                 <span class="n">conv1d_2</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span>                   
<span class="n">__________________________________________________________________________________________________</span>
<span class="n">conv1d_3</span> <span class="p">(</span><span class="n">Conv1D</span><span class="p">)</span>               <span class="p">(</span><span class="kc">None</span><span class="p">,</span> <span class="mi">256</span><span class="p">,</span> <span class="mi">16</span><span class="p">)</span>      <span class="mi">4112</span>        <span class="n">add</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span>                        
<span class="n">__________________________________________________________________________________________________</span>
<span class="n">activation_1</span> <span class="p">(</span><span class="n">Activation</span><span class="p">)</span>       <span class="p">(</span><span class="kc">None</span><span class="p">,</span> <span class="mi">256</span><span class="p">,</span> <span class="mi">16</span><span class="p">)</span>      <span class="mi">0</span>           <span class="n">conv1d_3</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span>                   
<span class="n">__________________________________________________________________________________________________</span>
<span class="n">lambda_1</span> <span class="p">(</span><span class="n">Lambda</span><span class="p">)</span>               <span class="p">(</span><span class="kc">None</span><span class="p">,</span> <span class="mi">256</span><span class="p">,</span> <span class="mi">16</span><span class="p">)</span>      <span class="mi">0</span>           <span class="n">activation_1</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span>               
<span class="n">__________________________________________________________________________________________________</span>
<span class="n">spatial_dropout1d_1</span> <span class="p">(</span><span class="n">SpatialDro</span> <span class="p">(</span><span class="kc">None</span><span class="p">,</span> <span class="mi">256</span><span class="p">,</span> <span class="mi">16</span><span class="p">)</span>      <span class="mi">0</span>           <span class="n">lambda_1</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span>                   
<span class="n">__________________________________________________________________________________________________</span>
<span class="n">conv1d_4</span> <span class="p">(</span><span class="n">Conv1D</span><span class="p">)</span>               <span class="p">(</span><span class="kc">None</span><span class="p">,</span> <span class="mi">256</span><span class="p">,</span> <span class="mi">16</span><span class="p">)</span>      <span class="mi">272</span>         <span class="n">spatial_dropout1d_1</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span>        
<span class="n">__________________________________________________________________________________________________</span>
<span class="n">add_1</span> <span class="p">(</span><span class="n">Add</span><span class="p">)</span>                     <span class="p">(</span><span class="kc">None</span><span class="p">,</span> <span class="mi">256</span><span class="p">,</span> <span class="mi">16</span><span class="p">)</span>      <span class="mi">0</span>           <span class="n">add</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span>                        
                                                                 <span class="n">conv1d_4</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span>                   
<span class="n">__________________________________________________________________________________________________</span>
<span class="n">conv1d_5</span> <span class="p">(</span><span class="n">Conv1D</span><span class="p">)</span>               <span class="p">(</span><span class="kc">None</span><span class="p">,</span> <span class="mi">256</span><span class="p">,</span> <span class="mi">16</span><span class="p">)</span>      <span class="mi">4112</span>        <span class="n">add_1</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span>                      
<span class="n">__________________________________________________________________________________________________</span>
<span class="n">activation_2</span> <span class="p">(</span><span class="n">Activation</span><span class="p">)</span>       <span class="p">(</span><span class="kc">None</span><span class="p">,</span> <span class="mi">256</span><span class="p">,</span> <span class="mi">16</span><span class="p">)</span>      <span class="mi">0</span>           <span class="n">conv1d_5</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span>                   
<span class="n">__________________________________________________________________________________________________</span>
<span class="n">lambda_2</span> <span class="p">(</span><span class="n">Lambda</span><span class="p">)</span>               <span class="p">(</span><span class="kc">None</span><span class="p">,</span> <span class="mi">256</span><span class="p">,</span> <span class="mi">16</span><span class="p">)</span>      <span class="mi">0</span>           <span class="n">activation_2</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span>               
<span class="n">__________________________________________________________________________________________________</span>
<span class="n">spatial_dropout1d_2</span> <span class="p">(</span><span class="n">SpatialDro</span> <span class="p">(</span><span class="kc">None</span><span class="p">,</span> <span class="mi">256</span><span class="p">,</span> <span class="mi">16</span><span class="p">)</span>      <span class="mi">0</span>           <span class="n">lambda_2</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span>                   
<span class="n">__________________________________________________________________________________________________</span>
<span class="n">conv1d_6</span> <span class="p">(</span><span class="n">Conv1D</span><span class="p">)</span>               <span class="p">(</span><span class="kc">None</span><span class="p">,</span> <span class="mi">256</span><span class="p">,</span> <span class="mi">16</span><span class="p">)</span>      <span class="mi">272</span>         <span class="n">spatial_dropout1d_2</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span>        
<span class="n">__________________________________________________________________________________________________</span>
<span class="n">add_2</span> <span class="p">(</span><span class="n">Add</span><span class="p">)</span>                     <span class="p">(</span><span class="kc">None</span><span class="p">,</span> <span class="mi">256</span><span class="p">,</span> <span class="mi">16</span><span class="p">)</span>      <span class="mi">0</span>           <span class="n">add_1</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span>                      
                                                                 <span class="n">conv1d_6</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span>                   
<span class="n">__________________________________________________________________________________________________</span>
<span class="n">conv1d_7</span> <span class="p">(</span><span class="n">Conv1D</span><span class="p">)</span>               <span class="p">(</span><span class="kc">None</span><span class="p">,</span> <span class="mi">256</span><span class="p">,</span> <span class="mi">16</span><span class="p">)</span>      <span class="mi">4112</span>        <span class="n">add_2</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span>                      
<span class="n">__________________________________________________________________________________________________</span>
<span class="n">activation_3</span> <span class="p">(</span><span class="n">Activation</span><span class="p">)</span>       <span class="p">(</span><span class="kc">None</span><span class="p">,</span> <span class="mi">256</span><span class="p">,</span> <span class="mi">16</span><span class="p">)</span>      <span class="mi">0</span>           <span class="n">conv1d_7</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span>                   
<span class="n">__________________________________________________________________________________________________</span>
<span class="n">lambda_3</span> <span class="p">(</span><span class="n">Lambda</span><span class="p">)</span>               <span class="p">(</span><span class="kc">None</span><span class="p">,</span> <span class="mi">256</span><span class="p">,</span> <span class="mi">16</span><span class="p">)</span>      <span class="mi">0</span>           <span class="n">activation_3</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span>               
<span class="n">__________________________________________________________________________________________________</span>
<span class="n">spatial_dropout1d_3</span> <span class="p">(</span><span class="n">SpatialDro</span> <span class="p">(</span><span class="kc">None</span><span class="p">,</span> <span class="mi">256</span><span class="p">,</span> <span class="mi">16</span><span class="p">)</span>      <span class="mi">0</span>           <span class="n">lambda_3</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span>                   
<span class="n">__________________________________________________________________________________________________</span>
<span class="n">conv1d_8</span> <span class="p">(</span><span class="n">Conv1D</span><span class="p">)</span>               <span class="p">(</span><span class="kc">None</span><span class="p">,</span> <span class="mi">256</span><span class="p">,</span> <span class="mi">16</span><span class="p">)</span>      <span class="mi">272</span>         <span class="n">spatial_dropout1d_3</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span>        
<span class="n">__________________________________________________________________________________________________</span>
<span class="n">add_3</span> <span class="p">(</span><span class="n">Add</span><span class="p">)</span>                     <span class="p">(</span><span class="kc">None</span><span class="p">,</span> <span class="mi">256</span><span class="p">,</span> <span class="mi">16</span><span class="p">)</span>      <span class="mi">0</span>           <span class="n">add_2</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span>                      
                                                                 <span class="n">conv1d_8</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span>                   
<span class="n">__________________________________________________________________________________________________</span>
<span class="n">conv1d_9</span> <span class="p">(</span><span class="n">Conv1D</span><span class="p">)</span>               <span class="p">(</span><span class="kc">None</span><span class="p">,</span> <span class="mi">256</span><span class="p">,</span> <span class="mi">16</span><span class="p">)</span>      <span class="mi">4112</span>        <span class="n">add_3</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span>                      
<span class="n">__________________________________________________________________________________________________</span>
<span class="n">activation_4</span> <span class="p">(</span><span class="n">Activation</span><span class="p">)</span>       <span class="p">(</span><span class="kc">None</span><span class="p">,</span> <span class="mi">256</span><span class="p">,</span> <span class="mi">16</span><span class="p">)</span>      <span class="mi">0</span>           <span class="n">conv1d_9</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span>                   
<span class="n">__________________________________________________________________________________________________</span>
<span class="n">lambda_4</span> <span class="p">(</span><span class="n">Lambda</span><span class="p">)</span>               <span class="p">(</span><span class="kc">None</span><span class="p">,</span> <span class="mi">256</span><span class="p">,</span> <span class="mi">16</span><span class="p">)</span>      <span class="mi">0</span>           <span class="n">activation_4</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span>               
<span class="n">__________________________________________________________________________________________________</span>
<span class="n">spatial_dropout1d_4</span> <span class="p">(</span><span class="n">SpatialDro</span> <span class="p">(</span><span class="kc">None</span><span class="p">,</span> <span class="mi">256</span><span class="p">,</span> <span class="mi">16</span><span class="p">)</span>      <span class="mi">0</span>           <span class="n">lambda_4</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span>                   
<span class="n">__________________________________________________________________________________________________</span>
<span class="n">conv1d_10</span> <span class="p">(</span><span class="n">Conv1D</span><span class="p">)</span>              <span class="p">(</span><span class="kc">None</span><span class="p">,</span> <span class="mi">256</span><span class="p">,</span> <span class="mi">16</span><span class="p">)</span>      <span class="mi">272</span>         <span class="n">spatial_dropout1d_4</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span>        
<span class="n">__________________________________________________________________________________________________</span>
<span class="n">add_4</span> <span class="p">(</span><span class="n">Add</span><span class="p">)</span>                     <span class="p">(</span><span class="kc">None</span><span class="p">,</span> <span class="mi">256</span><span class="p">,</span> <span class="mi">16</span><span class="p">)</span>      <span class="mi">0</span>           <span class="n">add_3</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span>                      
                                                                 <span class="n">conv1d_10</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span>                  
<span class="n">__________________________________________________________________________________________________</span>
<span class="n">conv1d_11</span> <span class="p">(</span><span class="n">Conv1D</span><span class="p">)</span>              <span class="p">(</span><span class="kc">None</span><span class="p">,</span> <span class="mi">256</span><span class="p">,</span> <span class="mi">16</span><span class="p">)</span>      <span class="mi">4112</span>        <span class="n">add_4</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span>                      
<span class="n">__________________________________________________________________________________________________</span>
<span class="n">activation_5</span> <span class="p">(</span><span class="n">Activation</span><span class="p">)</span>       <span class="p">(</span><span class="kc">None</span><span class="p">,</span> <span class="mi">256</span><span class="p">,</span> <span class="mi">16</span><span class="p">)</span>      <span class="mi">0</span>           <span class="n">conv1d_11</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span>                  
<span class="n">__________________________________________________________________________________________________</span>
<span class="n">lambda_5</span> <span class="p">(</span><span class="n">Lambda</span><span class="p">)</span>               <span class="p">(</span><span class="kc">None</span><span class="p">,</span> <span class="mi">256</span><span class="p">,</span> <span class="mi">16</span><span class="p">)</span>      <span class="mi">0</span>           <span class="n">activation_5</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span>               
<span class="n">__________________________________________________________________________________________________</span>
<span class="n">spatial_dropout1d_5</span> <span class="p">(</span><span class="n">SpatialDro</span> <span class="p">(</span><span class="kc">None</span><span class="p">,</span> <span class="mi">256</span><span class="p">,</span> <span class="mi">16</span><span class="p">)</span>      <span class="mi">0</span>           <span class="n">lambda_5</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span>                   
<span class="n">__________________________________________________________________________________________________</span>
<span class="n">conv1d_12</span> <span class="p">(</span><span class="n">Conv1D</span><span class="p">)</span>              <span class="p">(</span><span class="kc">None</span><span class="p">,</span> <span class="mi">256</span><span class="p">,</span> <span class="mi">16</span><span class="p">)</span>      <span class="mi">272</span>         <span class="n">spatial_dropout1d_5</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span>        
<span class="n">__________________________________________________________________________________________________</span>
<span class="n">add_5</span> <span class="p">(</span><span class="n">Add</span><span class="p">)</span>                     <span class="p">(</span><span class="kc">None</span><span class="p">,</span> <span class="mi">256</span><span class="p">,</span> <span class="mi">16</span><span class="p">)</span>      <span class="mi">0</span>           <span class="n">add_4</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span>                      
                                                                 <span class="n">conv1d_12</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span>                  
<span class="n">__________________________________________________________________________________________________</span>
<span class="n">conv1d_13</span> <span class="p">(</span><span class="n">Conv1D</span><span class="p">)</span>              <span class="p">(</span><span class="kc">None</span><span class="p">,</span> <span class="mi">256</span><span class="p">,</span> <span class="mi">16</span><span class="p">)</span>      <span class="mi">4112</span>        <span class="n">add_5</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span>                      
<span class="n">__________________________________________________________________________________________________</span>
<span class="n">activation_6</span> <span class="p">(</span><span class="n">Activation</span><span class="p">)</span>       <span class="p">(</span><span class="kc">None</span><span class="p">,</span> <span class="mi">256</span><span class="p">,</span> <span class="mi">16</span><span class="p">)</span>      <span class="mi">0</span>           <span class="n">conv1d_13</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span>                  
<span class="n">__________________________________________________________________________________________________</span>
<span class="n">lambda_6</span> <span class="p">(</span><span class="n">Lambda</span><span class="p">)</span>               <span class="p">(</span><span class="kc">None</span><span class="p">,</span> <span class="mi">256</span><span class="p">,</span> <span class="mi">16</span><span class="p">)</span>      <span class="mi">0</span>           <span class="n">activation_6</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span>               
<span class="n">__________________________________________________________________________________________________</span>
<span class="n">spatial_dropout1d_6</span> <span class="p">(</span><span class="n">SpatialDro</span> <span class="p">(</span><span class="kc">None</span><span class="p">,</span> <span class="mi">256</span><span class="p">,</span> <span class="mi">16</span><span class="p">)</span>      <span class="mi">0</span>           <span class="n">lambda_6</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span>                   
<span class="n">__________________________________________________________________________________________________</span>
<span class="n">conv1d_14</span> <span class="p">(</span><span class="n">Conv1D</span><span class="p">)</span>              <span class="p">(</span><span class="kc">None</span><span class="p">,</span> <span class="mi">256</span><span class="p">,</span> <span class="mi">16</span><span class="p">)</span>      <span class="mi">272</span>         <span class="n">spatial_dropout1d_6</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span>        
<span class="n">__________________________________________________________________________________________________</span>
<span class="n">add_6</span> <span class="p">(</span><span class="n">Add</span><span class="p">)</span>                     <span class="p">(</span><span class="kc">None</span><span class="p">,</span> <span class="mi">256</span><span class="p">,</span> <span class="mi">16</span><span class="p">)</span>      <span class="mi">0</span>           <span class="n">add_5</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span>                      
                                                                 <span class="n">conv1d_14</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span>                  
<span class="n">__________________________________________________________________________________________________</span>
<span class="n">conv1d_15</span> <span class="p">(</span><span class="n">Conv1D</span><span class="p">)</span>              <span class="p">(</span><span class="kc">None</span><span class="p">,</span> <span class="mi">256</span><span class="p">,</span> <span class="mi">16</span><span class="p">)</span>      <span class="mi">4112</span>        <span class="n">add_6</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span>                      
<span class="n">__________________________________________________________________________________________________</span>
<span class="n">activation_7</span> <span class="p">(</span><span class="n">Activation</span><span class="p">)</span>       <span class="p">(</span><span class="kc">None</span><span class="p">,</span> <span class="mi">256</span><span class="p">,</span> <span class="mi">16</span><span class="p">)</span>      <span class="mi">0</span>           <span class="n">conv1d_15</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span>                  
<span class="n">__________________________________________________________________________________________________</span>
<span class="n">lambda_7</span> <span class="p">(</span><span class="n">Lambda</span><span class="p">)</span>               <span class="p">(</span><span class="kc">None</span><span class="p">,</span> <span class="mi">256</span><span class="p">,</span> <span class="mi">16</span><span class="p">)</span>      <span class="mi">0</span>           <span class="n">activation_7</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span>               
<span class="n">__________________________________________________________________________________________________</span>
<span class="n">spatial_dropout1d_7</span> <span class="p">(</span><span class="n">SpatialDro</span> <span class="p">(</span><span class="kc">None</span><span class="p">,</span> <span class="mi">256</span><span class="p">,</span> <span class="mi">16</span><span class="p">)</span>      <span class="mi">0</span>           <span class="n">lambda_7</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span>                   
<span class="n">__________________________________________________________________________________________________</span>
<span class="n">conv1d_16</span> <span class="p">(</span><span class="n">Conv1D</span><span class="p">)</span>              <span class="p">(</span><span class="kc">None</span><span class="p">,</span> <span class="mi">256</span><span class="p">,</span> <span class="mi">16</span><span class="p">)</span>      <span class="mi">272</span>         <span class="n">spatial_dropout1d_7</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span>        
<span class="n">__________________________________________________________________________________________________</span>
<span class="n">add_7</span> <span class="p">(</span><span class="n">Add</span><span class="p">)</span>                     <span class="p">(</span><span class="kc">None</span><span class="p">,</span> <span class="mi">256</span><span class="p">,</span> <span class="mi">16</span><span class="p">)</span>      <span class="mi">0</span>           <span class="n">add_6</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span>                      
                                                                 <span class="n">conv1d_16</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span>                  
<span class="n">__________________________________________________________________________________________________</span>
<span class="n">conv1d_17</span> <span class="p">(</span><span class="n">Conv1D</span><span class="p">)</span>              <span class="p">(</span><span class="kc">None</span><span class="p">,</span> <span class="mi">256</span><span class="p">,</span> <span class="mi">16</span><span class="p">)</span>      <span class="mi">4112</span>        <span class="n">add_7</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span>                      
<span class="n">__________________________________________________________________________________________________</span>
<span class="n">activation_8</span> <span class="p">(</span><span class="n">Activation</span><span class="p">)</span>       <span class="p">(</span><span class="kc">None</span><span class="p">,</span> <span class="mi">256</span><span class="p">,</span> <span class="mi">16</span><span class="p">)</span>      <span class="mi">0</span>           <span class="n">conv1d_17</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span>                  
<span class="n">__________________________________________________________________________________________________</span>
<span class="n">lambda_8</span> <span class="p">(</span><span class="n">Lambda</span><span class="p">)</span>               <span class="p">(</span><span class="kc">None</span><span class="p">,</span> <span class="mi">256</span><span class="p">,</span> <span class="mi">16</span><span class="p">)</span>      <span class="mi">0</span>           <span class="n">activation_8</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span>               
<span class="n">__________________________________________________________________________________________________</span>
<span class="n">spatial_dropout1d_8</span> <span class="p">(</span><span class="n">SpatialDro</span> <span class="p">(</span><span class="kc">None</span><span class="p">,</span> <span class="mi">256</span><span class="p">,</span> <span class="mi">16</span><span class="p">)</span>      <span class="mi">0</span>           <span class="n">lambda_8</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span>                   
<span class="n">__________________________________________________________________________________________________</span>
<span class="n">conv1d_18</span> <span class="p">(</span><span class="n">Conv1D</span><span class="p">)</span>              <span class="p">(</span><span class="kc">None</span><span class="p">,</span> <span class="mi">256</span><span class="p">,</span> <span class="mi">16</span><span class="p">)</span>      <span class="mi">272</span>         <span class="n">spatial_dropout1d_8</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span>        
<span class="n">__________________________________________________________________________________________________</span>
<span class="n">add_8</span> <span class="p">(</span><span class="n">Add</span><span class="p">)</span>                     <span class="p">(</span><span class="kc">None</span><span class="p">,</span> <span class="mi">256</span><span class="p">,</span> <span class="mi">16</span><span class="p">)</span>      <span class="mi">0</span>           <span class="n">add_7</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span>                      
                                                                 <span class="n">conv1d_18</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span>                  
<span class="n">__________________________________________________________________________________________________</span>
<span class="n">conv1d_19</span> <span class="p">(</span><span class="n">Conv1D</span><span class="p">)</span>              <span class="p">(</span><span class="kc">None</span><span class="p">,</span> <span class="mi">256</span><span class="p">,</span> <span class="mi">16</span><span class="p">)</span>      <span class="mi">4112</span>        <span class="n">add_8</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span>                      
<span class="n">__________________________________________________________________________________________________</span>
<span class="n">activation_9</span> <span class="p">(</span><span class="n">Activation</span><span class="p">)</span>       <span class="p">(</span><span class="kc">None</span><span class="p">,</span> <span class="mi">256</span><span class="p">,</span> <span class="mi">16</span><span class="p">)</span>      <span class="mi">0</span>           <span class="n">conv1d_19</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span>                  
<span class="n">__________________________________________________________________________________________________</span>
<span class="n">lambda_9</span> <span class="p">(</span><span class="n">Lambda</span><span class="p">)</span>               <span class="p">(</span><span class="kc">None</span><span class="p">,</span> <span class="mi">256</span><span class="p">,</span> <span class="mi">16</span><span class="p">)</span>      <span class="mi">0</span>           <span class="n">activation_9</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span>               
<span class="n">__________________________________________________________________________________________________</span>
<span class="n">spatial_dropout1d_9</span> <span class="p">(</span><span class="n">SpatialDro</span> <span class="p">(</span><span class="kc">None</span><span class="p">,</span> <span class="mi">256</span><span class="p">,</span> <span class="mi">16</span><span class="p">)</span>      <span class="mi">0</span>           <span class="n">lambda_9</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span>                   
<span class="n">__________________________________________________________________________________________________</span>
<span class="n">conv1d_20</span> <span class="p">(</span><span class="n">Conv1D</span><span class="p">)</span>              <span class="p">(</span><span class="kc">None</span><span class="p">,</span> <span class="mi">256</span><span class="p">,</span> <span class="mi">16</span><span class="p">)</span>      <span class="mi">272</span>         <span class="n">spatial_dropout1d_9</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span>        
<span class="n">__________________________________________________________________________________________________</span>
<span class="n">add_9</span> <span class="p">(</span><span class="n">Add</span><span class="p">)</span>                     <span class="p">(</span><span class="kc">None</span><span class="p">,</span> <span class="mi">256</span><span class="p">,</span> <span class="mi">16</span><span class="p">)</span>      <span class="mi">0</span>           <span class="n">add_8</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span>                      
                                                                 <span class="n">conv1d_20</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span>                  
<span class="n">__________________________________________________________________________________________________</span>
<span class="n">conv1d_21</span> <span class="p">(</span><span class="n">Conv1D</span><span class="p">)</span>              <span class="p">(</span><span class="kc">None</span><span class="p">,</span> <span class="mi">256</span><span class="p">,</span> <span class="mi">16</span><span class="p">)</span>      <span class="mi">4112</span>        <span class="n">add_9</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span>                      
<span class="n">__________________________________________________________________________________________________</span>
<span class="n">activation_10</span> <span class="p">(</span><span class="n">Activation</span><span class="p">)</span>      <span class="p">(</span><span class="kc">None</span><span class="p">,</span> <span class="mi">256</span><span class="p">,</span> <span class="mi">16</span><span class="p">)</span>      <span class="mi">0</span>           <span class="n">conv1d_21</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span>                  
<span class="n">__________________________________________________________________________________________________</span>
<span class="n">lambda_10</span> <span class="p">(</span><span class="n">Lambda</span><span class="p">)</span>              <span class="p">(</span><span class="kc">None</span><span class="p">,</span> <span class="mi">256</span><span class="p">,</span> <span class="mi">16</span><span class="p">)</span>      <span class="mi">0</span>           <span class="n">activation_10</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span>              
<span class="n">__________________________________________________________________________________________________</span>
<span class="n">spatial_dropout1d_10</span> <span class="p">(</span><span class="n">SpatialDr</span> <span class="p">(</span><span class="kc">None</span><span class="p">,</span> <span class="mi">256</span><span class="p">,</span> <span class="mi">16</span><span class="p">)</span>      <span class="mi">0</span>           <span class="n">lambda_10</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span>                  
<span class="n">__________________________________________________________________________________________________</span>
<span class="n">conv1d_22</span> <span class="p">(</span><span class="n">Conv1D</span><span class="p">)</span>              <span class="p">(</span><span class="kc">None</span><span class="p">,</span> <span class="mi">256</span><span class="p">,</span> <span class="mi">16</span><span class="p">)</span>      <span class="mi">272</span>         <span class="n">spatial_dropout1d_10</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span>       
<span class="n">__________________________________________________________________________________________________</span>
<span class="n">add_10</span> <span class="p">(</span><span class="n">Add</span><span class="p">)</span>                    <span class="p">(</span><span class="kc">None</span><span class="p">,</span> <span class="mi">256</span><span class="p">,</span> <span class="mi">16</span><span class="p">)</span>      <span class="mi">0</span>           <span class="n">add_9</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span>                      
                                                                 <span class="n">conv1d_22</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span>                  
<span class="n">__________________________________________________________________________________________________</span>
<span class="n">conv1d_23</span> <span class="p">(</span><span class="n">Conv1D</span><span class="p">)</span>              <span class="p">(</span><span class="kc">None</span><span class="p">,</span> <span class="mi">256</span><span class="p">,</span> <span class="mi">16</span><span class="p">)</span>      <span class="mi">4112</span>        <span class="n">add_10</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span>                     
<span class="n">__________________________________________________________________________________________________</span>
<span class="n">activation_11</span> <span class="p">(</span><span class="n">Activation</span><span class="p">)</span>      <span class="p">(</span><span class="kc">None</span><span class="p">,</span> <span class="mi">256</span><span class="p">,</span> <span class="mi">16</span><span class="p">)</span>      <span class="mi">0</span>           <span class="n">conv1d_23</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span>                  
<span class="n">__________________________________________________________________________________________________</span>
<span class="n">lambda_11</span> <span class="p">(</span><span class="n">Lambda</span><span class="p">)</span>              <span class="p">(</span><span class="kc">None</span><span class="p">,</span> <span class="mi">256</span><span class="p">,</span> <span class="mi">16</span><span class="p">)</span>      <span class="mi">0</span>           <span class="n">activation_11</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span>              
<span class="n">__________________________________________________________________________________________________</span>
<span class="n">spatial_dropout1d_11</span> <span class="p">(</span><span class="n">SpatialDr</span> <span class="p">(</span><span class="kc">None</span><span class="p">,</span> <span class="mi">256</span><span class="p">,</span> <span class="mi">16</span><span class="p">)</span>      <span class="mi">0</span>           <span class="n">lambda_11</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span>                  
<span class="n">__________________________________________________________________________________________________</span>
<span class="n">conv1d_24</span> <span class="p">(</span><span class="n">Conv1D</span><span class="p">)</span>              <span class="p">(</span><span class="kc">None</span><span class="p">,</span> <span class="mi">256</span><span class="p">,</span> <span class="mi">16</span><span class="p">)</span>      <span class="mi">272</span>         <span class="n">spatial_dropout1d_11</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span>       
<span class="n">__________________________________________________________________________________________________</span>
<span class="n">add_11</span> <span class="p">(</span><span class="n">Add</span><span class="p">)</span>                    <span class="p">(</span><span class="kc">None</span><span class="p">,</span> <span class="mi">256</span><span class="p">,</span> <span class="mi">16</span><span class="p">)</span>      <span class="mi">0</span>           <span class="n">add_10</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span>                     
                                                                 <span class="n">conv1d_24</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span>                  
<span class="n">__________________________________________________________________________________________________</span>
<span class="n">conv1d_25</span> <span class="p">(</span><span class="n">Conv1D</span><span class="p">)</span>              <span class="p">(</span><span class="kc">None</span><span class="p">,</span> <span class="mi">256</span><span class="p">,</span> <span class="mi">16</span><span class="p">)</span>      <span class="mi">4112</span>        <span class="n">add_11</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span>                     
<span class="n">__________________________________________________________________________________________________</span>
<span class="n">activation_12</span> <span class="p">(</span><span class="n">Activation</span><span class="p">)</span>      <span class="p">(</span><span class="kc">None</span><span class="p">,</span> <span class="mi">256</span><span class="p">,</span> <span class="mi">16</span><span class="p">)</span>      <span class="mi">0</span>           <span class="n">conv1d_25</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span>                  
<span class="n">__________________________________________________________________________________________________</span>
<span class="n">lambda_12</span> <span class="p">(</span><span class="n">Lambda</span><span class="p">)</span>              <span class="p">(</span><span class="kc">None</span><span class="p">,</span> <span class="mi">256</span><span class="p">,</span> <span class="mi">16</span><span class="p">)</span>      <span class="mi">0</span>           <span class="n">activation_12</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span>              
<span class="n">__________________________________________________________________________________________________</span>
<span class="n">spatial_dropout1d_12</span> <span class="p">(</span><span class="n">SpatialDr</span> <span class="p">(</span><span class="kc">None</span><span class="p">,</span> <span class="mi">256</span><span class="p">,</span> <span class="mi">16</span><span class="p">)</span>      <span class="mi">0</span>           <span class="n">lambda_12</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span>                  
<span class="n">__________________________________________________________________________________________________</span>
<span class="n">conv1d_26</span> <span class="p">(</span><span class="n">Conv1D</span><span class="p">)</span>              <span class="p">(</span><span class="kc">None</span><span class="p">,</span> <span class="mi">256</span><span class="p">,</span> <span class="mi">16</span><span class="p">)</span>      <span class="mi">272</span>         <span class="n">spatial_dropout1d_12</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span>       
<span class="n">__________________________________________________________________________________________________</span>
<span class="n">add_12</span> <span class="p">(</span><span class="n">Add</span><span class="p">)</span>                    <span class="p">(</span><span class="kc">None</span><span class="p">,</span> <span class="mi">256</span><span class="p">,</span> <span class="mi">16</span><span class="p">)</span>      <span class="mi">0</span>           <span class="n">add_11</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span>                     
                                                                 <span class="n">conv1d_26</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span>                  
<span class="n">__________________________________________________________________________________________________</span>
<span class="n">conv1d_27</span> <span class="p">(</span><span class="n">Conv1D</span><span class="p">)</span>              <span class="p">(</span><span class="kc">None</span><span class="p">,</span> <span class="mi">256</span><span class="p">,</span> <span class="mi">16</span><span class="p">)</span>      <span class="mi">4112</span>        <span class="n">add_12</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span>                     
<span class="n">__________________________________________________________________________________________________</span>
<span class="n">activation_13</span> <span class="p">(</span><span class="n">Activation</span><span class="p">)</span>      <span class="p">(</span><span class="kc">None</span><span class="p">,</span> <span class="mi">256</span><span class="p">,</span> <span class="mi">16</span><span class="p">)</span>      <span class="mi">0</span>           <span class="n">conv1d_27</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span>                  
<span class="n">__________________________________________________________________________________________________</span>
<span class="n">lambda_13</span> <span class="p">(</span><span class="n">Lambda</span><span class="p">)</span>              <span class="p">(</span><span class="kc">None</span><span class="p">,</span> <span class="mi">256</span><span class="p">,</span> <span class="mi">16</span><span class="p">)</span>      <span class="mi">0</span>           <span class="n">activation_13</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span>              
<span class="n">__________________________________________________________________________________________________</span>
<span class="n">spatial_dropout1d_13</span> <span class="p">(</span><span class="n">SpatialDr</span> <span class="p">(</span><span class="kc">None</span><span class="p">,</span> <span class="mi">256</span><span class="p">,</span> <span class="mi">16</span><span class="p">)</span>      <span class="mi">0</span>           <span class="n">lambda_13</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span>                  
<span class="n">__________________________________________________________________________________________________</span>
<span class="n">conv1d_28</span> <span class="p">(</span><span class="n">Conv1D</span><span class="p">)</span>              <span class="p">(</span><span class="kc">None</span><span class="p">,</span> <span class="mi">256</span><span class="p">,</span> <span class="mi">16</span><span class="p">)</span>      <span class="mi">272</span>         <span class="n">spatial_dropout1d_13</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span>       
<span class="n">__________________________________________________________________________________________________</span>
<span class="n">add_13</span> <span class="p">(</span><span class="n">Add</span><span class="p">)</span>                    <span class="p">(</span><span class="kc">None</span><span class="p">,</span> <span class="mi">256</span><span class="p">,</span> <span class="mi">16</span><span class="p">)</span>      <span class="mi">0</span>           <span class="n">add_12</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span>                     
                                                                 <span class="n">conv1d_28</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span>                  
<span class="n">__________________________________________________________________________________________________</span>
<span class="n">conv1d_29</span> <span class="p">(</span><span class="n">Conv1D</span><span class="p">)</span>              <span class="p">(</span><span class="kc">None</span><span class="p">,</span> <span class="mi">256</span><span class="p">,</span> <span class="mi">16</span><span class="p">)</span>      <span class="mi">4112</span>        <span class="n">add_13</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span>                     
<span class="n">__________________________________________________________________________________________________</span>
<span class="n">activation_14</span> <span class="p">(</span><span class="n">Activation</span><span class="p">)</span>      <span class="p">(</span><span class="kc">None</span><span class="p">,</span> <span class="mi">256</span><span class="p">,</span> <span class="mi">16</span><span class="p">)</span>      <span class="mi">0</span>           <span class="n">conv1d_29</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span>                  
<span class="n">__________________________________________________________________________________________________</span>
<span class="n">lambda_14</span> <span class="p">(</span><span class="n">Lambda</span><span class="p">)</span>              <span class="p">(</span><span class="kc">None</span><span class="p">,</span> <span class="mi">256</span><span class="p">,</span> <span class="mi">16</span><span class="p">)</span>      <span class="mi">0</span>           <span class="n">activation_14</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span>              
<span class="n">__________________________________________________________________________________________________</span>
<span class="n">spatial_dropout1d_14</span> <span class="p">(</span><span class="n">SpatialDr</span> <span class="p">(</span><span class="kc">None</span><span class="p">,</span> <span class="mi">256</span><span class="p">,</span> <span class="mi">16</span><span class="p">)</span>      <span class="mi">0</span>           <span class="n">lambda_14</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span>                  
<span class="n">__________________________________________________________________________________________________</span>
<span class="n">conv1d_30</span> <span class="p">(</span><span class="n">Conv1D</span><span class="p">)</span>              <span class="p">(</span><span class="kc">None</span><span class="p">,</span> <span class="mi">256</span><span class="p">,</span> <span class="mi">16</span><span class="p">)</span>      <span class="mi">272</span>         <span class="n">spatial_dropout1d_14</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span>       
<span class="n">__________________________________________________________________________________________________</span>
<span class="n">add_15</span> <span class="p">(</span><span class="n">Add</span><span class="p">)</span>                    <span class="p">(</span><span class="kc">None</span><span class="p">,</span> <span class="mi">256</span><span class="p">,</span> <span class="mi">16</span><span class="p">)</span>      <span class="mi">0</span>           <span class="n">conv1d_2</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span>                   
                                                                 <span class="n">conv1d_4</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span>                   
                                                                 <span class="n">conv1d_6</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span>                   
                                                                 <span class="n">conv1d_8</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span>                   
                                                                 <span class="n">conv1d_10</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span>                  
                                                                 <span class="n">conv1d_12</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span>                  
                                                                 <span class="n">conv1d_14</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span>                  
                                                                 <span class="n">conv1d_16</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span>                  
                                                                 <span class="n">conv1d_18</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span>                  
                                                                 <span class="n">conv1d_20</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span>                  
                                                                 <span class="n">conv1d_22</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span>                  
                                                                 <span class="n">conv1d_24</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span>                  
                                                                 <span class="n">conv1d_26</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span>                  
                                                                 <span class="n">conv1d_28</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span>                  
                                                                 <span class="n">conv1d_30</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span>                  
<span class="n">__________________________________________________________________________________________________</span>
<span class="n">activation_15</span> <span class="p">(</span><span class="n">Activation</span><span class="p">)</span>      <span class="p">(</span><span class="kc">None</span><span class="p">,</span> <span class="mi">256</span><span class="p">,</span> <span class="mi">16</span><span class="p">)</span>      <span class="mi">0</span>           <span class="n">add_15</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span>                     
<span class="n">__________________________________________________________________________________________________</span>
<span class="n">dense</span> <span class="p">(</span><span class="n">Dense</span><span class="p">)</span>                   <span class="p">(</span><span class="kc">None</span><span class="p">,</span> <span class="mi">256</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>       <span class="mi">51</span>          <span class="n">activation_15</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span>              
<span class="n">__________________________________________________________________________________________________</span>
<span class="n">activation_16</span> <span class="p">(</span><span class="n">Activation</span><span class="p">)</span>      <span class="p">(</span><span class="kc">None</span><span class="p">,</span> <span class="mi">256</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>       <span class="mi">0</span>           <span class="n">dense</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span>                      
<span class="o">==================================================================================================</span>
<span class="n">Total</span> <span class="n">params</span><span class="p">:</span> <span class="mi">65</span><span class="p">,</span><span class="mi">843</span>
<span class="n">Trainable</span> <span class="n">params</span><span class="p">:</span> <span class="mi">65</span><span class="p">,</span><span class="mi">843</span>
<span class="n">Non</span><span class="o">-</span><span class="n">trainable</span> <span class="n">params</span><span class="p">:</span> <span class="mi">0</span>
<span class="n">__________________________________________________________________________________________________</span>
<span class="n">Epoch</span> <span class="mi">1</span><span class="o">/</span><span class="mi">4</span>
 <span class="mi">999</span><span class="o">/</span><span class="mi">1000</span> <span class="p">[</span><span class="o">============================&gt;.</span><span class="p">]</span> <span class="o">-</span> <span class="n">ETA</span><span class="p">:</span> <span class="mi">0</span><span class="n">s</span> <span class="o">-</span> <span class="n">loss</span><span class="p">:</span> <span class="mf">0.1099</span><span class="n">Epoch</span> <span class="mi">1</span><span class="o">/</span><span class="mi">4</span>
 <span class="mi">810</span><span class="o">/</span><span class="mi">1000</span> <span class="p">[</span><span class="o">=======================&gt;......</span><span class="p">]</span> <span class="o">-</span> <span class="n">ETA</span><span class="p">:</span> <span class="mi">3</span><span class="n">s</span> <span class="o">-</span> <span class="n">loss</span><span class="p">:</span> <span class="mf">0.1113</span>
<span class="n">Epoch</span> <span class="mi">00001</span><span class="p">:</span> <span class="n">val_loss</span> <span class="n">improved</span> <span class="kn">from</span> <span class="nn">inf</span> <span class="n">to</span> <span class="mf">0.11132</span><span class="p">,</span> <span class="n">saving</span> <span class="n">model</span> <span class="n">to</span> <span class="n">res</span><span class="o">/</span><span class="mi">20201207_082948</span><span class="n">_model</span><span class="o">.</span><span class="n">h5</span>
<span class="mi">1000</span><span class="o">/</span><span class="mi">1000</span> <span class="p">[</span><span class="o">==============================</span><span class="p">]</span> <span class="o">-</span> <span class="mi">159</span><span class="n">s</span> <span class="mi">159</span><span class="n">ms</span><span class="o">/</span><span class="n">step</span> <span class="o">-</span> <span class="n">loss</span><span class="p">:</span> <span class="mf">0.1100</span> <span class="o">-</span> <span class="n">val_loss</span><span class="p">:</span> <span class="mf">0.1113</span>
<span class="n">Epoch</span> <span class="mi">2</span><span class="o">/</span><span class="mi">4</span>
 <span class="mi">999</span><span class="o">/</span><span class="mi">1000</span> <span class="p">[</span><span class="o">============================&gt;.</span><span class="p">]</span> <span class="o">-</span> <span class="n">ETA</span><span class="p">:</span> <span class="mi">0</span><span class="n">s</span> <span class="o">-</span> <span class="n">loss</span><span class="p">:</span> <span class="mf">0.0830</span><span class="n">Epoch</span> <span class="mi">1</span><span class="o">/</span><span class="mi">4</span>
 <span class="mi">811</span><span class="o">/</span><span class="mi">1000</span> <span class="p">[</span><span class="o">=======================&gt;......</span><span class="p">]</span> <span class="o">-</span> <span class="n">ETA</span><span class="p">:</span> <span class="mi">2</span><span class="n">s</span> <span class="o">-</span> <span class="n">loss</span><span class="p">:</span> <span class="mf">0.1283</span>
<span class="n">Epoch</span> <span class="mi">00002</span><span class="p">:</span> <span class="n">val_loss</span> <span class="n">did</span> <span class="ow">not</span> <span class="n">improve</span> <span class="kn">from</span> <span class="mf">0.11132</span>
<span class="mi">1000</span><span class="o">/</span><span class="mi">1000</span> <span class="p">[</span><span class="o">==============================</span><span class="p">]</span> <span class="o">-</span> <span class="mi">154</span><span class="n">s</span> <span class="mi">154</span><span class="n">ms</span><span class="o">/</span><span class="n">step</span> <span class="o">-</span> <span class="n">loss</span><span class="p">:</span> <span class="mf">0.0831</span> <span class="o">-</span> <span class="n">val_loss</span><span class="p">:</span> <span class="mf">0.1285</span>
<span class="n">Epoch</span> <span class="mi">3</span><span class="o">/</span><span class="mi">4</span>
 <span class="mi">999</span><span class="o">/</span><span class="mi">1000</span> <span class="p">[</span><span class="o">============================&gt;.</span><span class="p">]</span> <span class="o">-</span> <span class="n">ETA</span><span class="p">:</span> <span class="mi">0</span><span class="n">s</span> <span class="o">-</span> <span class="n">loss</span><span class="p">:</span> <span class="mf">0.0827</span><span class="n">Epoch</span> <span class="mi">1</span><span class="o">/</span><span class="mi">4</span>
 <span class="mi">811</span><span class="o">/</span><span class="mi">1000</span> <span class="p">[</span><span class="o">=======================&gt;......</span><span class="p">]</span> <span class="o">-</span> <span class="n">ETA</span><span class="p">:</span> <span class="mi">3</span><span class="n">s</span> <span class="o">-</span> <span class="n">loss</span><span class="p">:</span> <span class="mf">0.1090</span>
<span class="n">Epoch</span> <span class="mi">00003</span><span class="p">:</span> <span class="n">val_loss</span> <span class="n">improved</span> <span class="kn">from</span> <span class="mf">0.11132</span> <span class="n">to</span> <span class="mf">0.10919</span><span class="p">,</span> <span class="n">saving</span> <span class="n">model</span> <span class="n">to</span> <span class="n">res</span><span class="o">/</span><span class="mi">20201207_082948</span><span class="n">_model</span><span class="o">.</span><span class="n">h5</span>
<span class="mi">1000</span><span class="o">/</span><span class="mi">1000</span> <span class="p">[</span><span class="o">==============================</span><span class="p">]</span> <span class="o">-</span> <span class="mi">159</span><span class="n">s</span> <span class="mi">159</span><span class="n">ms</span><span class="o">/</span><span class="n">step</span> <span class="o">-</span> <span class="n">loss</span><span class="p">:</span> <span class="mf">0.0827</span> <span class="o">-</span> <span class="n">val_loss</span><span class="p">:</span> <span class="mf">0.1092</span>
<span class="n">Epoch</span> <span class="mi">4</span><span class="o">/</span><span class="mi">4</span>
 <span class="mi">999</span><span class="o">/</span><span class="mi">1000</span> <span class="p">[</span><span class="o">============================&gt;.</span><span class="p">]</span> <span class="o">-</span> <span class="n">ETA</span><span class="p">:</span> <span class="mi">0</span><span class="n">s</span> <span class="o">-</span> <span class="n">loss</span><span class="p">:</span> <span class="mf">0.0814</span><span class="n">Epoch</span> <span class="mi">1</span><span class="o">/</span><span class="mi">4</span>
 <span class="mi">812</span><span class="o">/</span><span class="mi">1000</span> <span class="p">[</span><span class="o">=======================&gt;......</span><span class="p">]</span> <span class="o">-</span> <span class="n">ETA</span><span class="p">:</span> <span class="mi">3</span><span class="n">s</span> <span class="o">-</span> <span class="n">loss</span><span class="p">:</span> <span class="mf">0.1116</span>
<span class="n">Epoch</span> <span class="mi">00004</span><span class="p">:</span> <span class="n">val_loss</span> <span class="n">did</span> <span class="ow">not</span> <span class="n">improve</span> <span class="kn">from</span> <span class="mf">0.10919</span>
<span class="mi">1000</span><span class="o">/</span><span class="mi">1000</span> <span class="p">[</span><span class="o">==============================</span><span class="p">]</span> <span class="o">-</span> <span class="mi">166</span><span class="n">s</span> <span class="mi">166</span><span class="n">ms</span><span class="o">/</span><span class="n">step</span> <span class="o">-</span> <span class="n">loss</span><span class="p">:</span> <span class="mf">0.0814</span> <span class="o">-</span> <span class="n">val_loss</span><span class="p">:</span> <span class="mf">0.1116</span>
<span class="n">INFO</span><span class="p">:</span><span class="n">root</span><span class="p">:</span><span class="n">re</span><span class="o">-</span><span class="n">loading</span> <span class="n">last</span> <span class="n">best</span> <span class="n">model</span>
<span class="n">INFO</span><span class="p">:</span><span class="n">root</span><span class="p">:</span><span class="n">predicting</span>
<span class="mi">777</span><span class="o">/</span><span class="mi">777</span> <span class="p">[</span><span class="o">==============================</span><span class="p">]</span> <span class="o">-</span> <span class="mi">14</span><span class="n">s</span> <span class="mi">18</span><span class="n">ms</span><span class="o">/</span><span class="n">step</span>
<span class="n">INFO</span><span class="p">:</span><span class="n">root</span><span class="p">:</span><span class="n">evaluating</span>
<span class="n">INFO</span><span class="p">:</span><span class="n">root</span><span class="p">:[[</span><span class="mi">3555131</span>    <span class="mi">6458</span>   <span class="mi">30969</span><span class="p">]</span>
 <span class="p">[</span>  <span class="mi">12403</span>   <span class="mi">31631</span>     <span class="mi">274</span><span class="p">]</span>
 <span class="p">[</span> <span class="mi">113317</span>      <span class="mi">55</span>  <span class="mi">228002</span><span class="p">]]</span>
<span class="n">INFO</span><span class="p">:</span><span class="n">root</span><span class="p">:</span>              <span class="n">precision</span>    <span class="n">recall</span>  <span class="n">f1</span><span class="o">-</span><span class="n">score</span>   <span class="n">support</span>

       <span class="n">noise</span>      <span class="mf">0.966</span>     <span class="mf">0.990</span>     <span class="mf">0.978</span>   <span class="mi">3592558</span>
       <span class="n">pulse</span>      <span class="mf">0.829</span>     <span class="mf">0.714</span>     <span class="mf">0.767</span>     <span class="mi">44308</span>
        <span class="n">sine</span>      <span class="mf">0.879</span>     <span class="mf">0.668</span>     <span class="mf">0.759</span>    <span class="mi">341374</span>

    <span class="n">accuracy</span>                          <span class="mf">0.959</span>   <span class="mi">3978240</span>
   <span class="n">macro</span> <span class="n">avg</span>      <span class="mf">0.892</span>     <span class="mf">0.790</span>     <span class="mf">0.835</span>   <span class="mi">3978240</span>
<span class="n">weighted</span> <span class="n">avg</span>      <span class="mf">0.957</span>     <span class="mf">0.959</span>     <span class="mf">0.956</span>   <span class="mi">3978240</span>

<span class="n">INFO</span><span class="p">:</span><span class="n">root</span><span class="p">:</span><span class="n">saving</span> <span class="n">to</span> <span class="n">res</span><span class="o">/</span><span class="mi">20201207_082948</span><span class="n">_results</span><span class="o">.</span><span class="n">h5</span><span class="o">.</span>
</pre></div>
</div>
</div>
<div class="section" id="training-using-command-line-scripts">
<h2>Training using command-line scripts<a class="headerlink" href="#training-using-command-line-scripts" title="Permalink to this headline">¶</a></h2>
<p>The training function <code class="docutils literal notranslate"><span class="pre">dss.train.train</span></code> and all its arguments are also accessible from the command line via <code class="docutils literal notranslate"><span class="pre">dss</span> <span class="pre">train</span></code> for use on the terminal. See <a class="reference internal" href="../technical/cli.html"><span class="doc std std-doc">here</span></a> for a description of all command-line arguments. The command-line interface is generated with <a class="reference external" href="https://defopt.readthedocs.io/en/stable/index.html">defopt</a>.</p>
<p>For instance, training commaned above can be invoked from the command line:</p>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span>dss train --data-dir dat/dmel_single_raw.npy --save-dir res --model-name tcn --kernel-size <span class="m">16</span> --nb-filters <span class="m">16</span> --nb-hist <span class="m">512</span> --nb-epoch <span class="m">20</span> -i
</pre></div>
</div>
<p>Shell scripts are particularly useful if you want to fit a set of networks with with different configurations to optimize architecture. For instance, this scripts will fit networks with different numbers of TCN blocks (<code class="docutils literal notranslate"><span class="pre">nb_conv</span></code>) and filters (<code class="docutils literal notranslate"><span class="pre">nb_filters</span></code>):</p>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span><span class="ch">#!/bin/bash</span>
conda activate dss

<span class="nv">YSUFFIX</span><span class="o">=</span><span class="s2">&quot;pulse&quot;</span>
<span class="nv">MODELNAME</span><span class="o">=</span><span class="s1">&#39;tcn&#39;</span>
<span class="nv">DATADIR</span><span class="o">=</span><span class="s1">&#39;../dat/dmel_single.npy&#39;</span>
<span class="nv">SAVEDIR</span><span class="o">=</span><span class="s2">&quot;res&quot;</span>

<span class="nv">NB_HIST</span><span class="o">=</span><span class="m">2048</span>
<span class="nv">KERNEL_SIZE</span><span class="o">=</span><span class="m">32</span>
<span class="nv">NB_FILTERS</span><span class="o">=</span><span class="m">32</span>
<span class="nv">NB_CONV</span><span class="o">=</span><span class="m">3</span>

<span class="k">for</span> NB_CONV in <span class="m">2</span> <span class="m">3</span> <span class="m">4</span>
<span class="k">do</span>
    <span class="k">for</span> NB_FILTERS in <span class="m">16</span> <span class="m">32</span> <span class="m">48</span> <span class="m">64</span>
    <span class="k">do</span>
        dss train -i --nb-filters <span class="nv">$NB_FILTERS</span> --kernel-size <span class="nv">$KERNEL_SIZE</span> --nb-conv <span class="nv">$NB_CONV</span> --nb-hist <span class="nv">$NB_HIST</span> --save-dir <span class="nv">$SAVEDIR</span> --y-suffix <span class="nv">$YSUFFIX</span> --data-dir <span class="nv">$DATADIR</span> --model-name <span class="nv">$MODELNAME</span>
    <span class="k">done</span>
<span class="k">done</span>
</pre></div>
</div>
<p>A description of all command line arguments can be obtained by typing <code class="docutils literal notranslate"><span class="pre">dss</span> <span class="pre">train</span> <span class="pre">--help</span></code> in a terminal:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">!</span>dss train --help
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>usage: dss train [-h] -d DATA_DIR [-y Y_SUFFIX] [--save-dir SAVE_DIR]
                 [--save-prefix SAVE_PREFIX] [-m MODEL_NAME]
                 [--nb-filters NB_FILTERS] [-k KERNEL_SIZE]
                 [--nb-conv NB_CONV] [-u [USE_SEPARABLE [USE_SEPARABLE ...]]]
                 [--nb-hist NB_HIST] [-i] [--no-ignore-boundaries]
                 [--batch-norm] [--no-batch-norm] [--nb-pre-conv NB_PRE_CONV]
                 [--pre-kernel-size PRE_KERNEL_SIZE]
                 [--pre-nb-filters PRE_NB_FILTERS] [--pre-nb-conv PRE_NB_CONV]
                 [-v VERBOSE] [--batch-size BATCH_SIZE] [--nb-epoch NB_EPOCH]
                 [--learning-rate LEARNING_RATE] [--reduce-lr]
                 [--no-reduce-lr] [--reduce-lr-patience REDUCE_LR_PATIENCE]
                 [-f FRACTION_DATA] [--seed SEED] [--batch-level-subsampling]
                 [--no-batch-level-subsampling] [-t] [--no-tensorboard]
                 [--log-messages] [--no-log-messages] [--nb-stacks NB_STACKS]
                 [-w] [--no-with-y-hist] [-x X_SUFFIX]

Train a DeepSS network.

optional arguments:
  -h, --help            show this help message and exit
  -d DATA_DIR, --data-dir DATA_DIR
                        Path to the directory or file with the dataset for training.
                        Accepts npy-dirs (recommended), h5 files or zarr files.
                        See documentation for how the dataset should be organized.
  -y Y_SUFFIX, --y-suffix Y_SUFFIX
                        Select training target by suffix.
                        Song-type specific targets can be created with a training dataset,
                        Defaults to &#39;&#39; (will use the standard target &#39;y&#39;)
  --save-dir SAVE_DIR   Directory to save training outputs.
                        The path of output files will constructed from the SAVE_DIR, an optional prefix, and the time stamp of the start of training.
                        Defaults to current directory (&#39;./&#39;).
  --save-prefix SAVE_PREFIX
                        Prepend to timestamp.
                        Name of files created will be SAVE_DIR/SAVE_PREFIX + &quot;_&quot; + TIMESTAMP
                        or SAVE_DIR/ TIMESTAMP if SAVE_PREFIX is empty.
                        Defaults to &#39;&#39; (empty).
  -m MODEL_NAME, --model-name MODEL_NAME
                        Network architecture to use.
                        Use &quot;tcn&quot; (TCN) or &quot;tcn_stft&quot; (TCN with STFT frontend).
                        See dss.models for a description of all models.
                        Defaults to &#39;tcn&#39;.
  --nb-filters NB_FILTERS
                        Number of filters per layer.
                        Defaults to 16.
  -k KERNEL_SIZE, --kernel-size KERNEL_SIZE
                        Duration of the filters (=kernels) in samples.
                        Defaults to 16.
  --nb-conv NB_CONV     Number of TCN blocks in the network.
                        Defaults to 3.
  -u [USE_SEPARABLE [USE_SEPARABLE ...]], --use-separable [USE_SEPARABLE [USE_SEPARABLE ...]]
                        Specify which TCN blocks should use separable convolutions.
                        Provide as a space-separated sequence of &quot;False&quot; or &quot;True.
                        For instance: &quot;True False False&quot; will set the first block in a
                        three-block (as given by nb_conv) network to use separable convolutions.
                        Defaults to False (no block uses separable convolution).
  --nb-hist NB_HIST     Number of samples processed at once by the network (a.k.a chunk size).
                        Defaults to 1024.
  -i, --ignore-boundaries
                        Minimize edge effects by discarding predictions at the edges of chunks.
                        Defaults to True.
  --no-ignore-boundaries
  --batch-norm          Batch normalize.
                        Defaults to True.
  --no-batch-norm
  --nb-pre-conv NB_PRE_CONV
                        Adds downsampling frontend.
                        TCN: adds a frontend of N conv blocks (conv-relu-batchnorm-maxpool2) to the TCN - useful for reducing the sampling rate for USV.
                        TCN_STFT: stft
                        Defaults to 0 (no frontend).
  --pre-kernel-size PRE_KERNEL_SIZE
                        [description]. Defaults to 3.
  --pre-nb-filters PRE_NB_FILTERS
                        [description]. Defaults to 16.
  --pre-nb-conv PRE_NB_CONV
                        [description]. Defaults to 3.
  -v VERBOSE, --verbose VERBOSE
                        Verbosity of training output (0 - no output(?), 1 - progress bar, 2 - one line per epoch).
                        Defaults to 2.
  --batch-size BATCH_SIZE
                        Batch size
                        Defaults to 32.
  --nb-epoch NB_EPOCH   Maximal number of training epochs.
                        Training will stop early if validation loss did not decrease in the last 20 epochs.
                        Defaults to 400.
  --learning-rate LEARNING_RATE
                        Learning rate of the model. Defaults should work in most cases.
                        Values typically range between 0.1 and 0.00001.
                        If None, uses per model defaults: &quot;tcn&quot; 0.0001, &quot;tcn_stft&quot; 0.0005).
                        Defaults to None.
  --reduce-lr           Reduce learning rate on plateau.
                        Defaults to False.
  --no-reduce-lr
  --reduce-lr-patience REDUCE_LR_PATIENCE
                        Number of epochs w/o a reduction in validation loss after which to trigger a reduction in learning rate.
                        Defaults to 5.
  -f FRACTION_DATA, --fraction-data FRACTION_DATA
                        Fraction of training and validation to use for training.
                        Defaults to 1.0.
  --seed SEED           Random seed to reproducible select fractions of the data.
                        Defaults to None (no seed).
  --batch-level-subsampling
                        Select fraction of data for training from random subset of shuffled batches.
                        If False, select a continuous chunk of the recording.
                        Defaults to False.
  --no-batch-level-subsampling
  -t, --tensorboard     Write tensorboard logs to save_dir.
                        Defaults to False.
  --no-tensorboard
  --log-messages        Sets logging level to INFO.
                        Defaults to False (will follow existing settings).
  --no-log-messages
  --nb-stacks NB_STACKS
                        Unused if model name is &quot;tcn&quot; or &quot;tcn_stft&quot;. Defaults to 2.
  -w, --with-y-hist     Unused if model name is &quot;tcn&quot; or &quot;tcn_stft&quot;. Defaults to True.
  --no-with-y-hist
  -x X_SUFFIX, --x-suffix X_SUFFIX
                        Select specific training data based on suffix (e.g. x_suffix).
                        Defaults to &#39;&#39; (will use the standard data &#39;x&#39;)

</pre></div>
</div>
</div>
</div>
</div>
</div>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./tutorials"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
        </div>
    </div>
    
    
    <div class='prev-next-bottom'>
        
    <a class='left-prev' id="prev-link" href="inspect_dataset.html" title="previous page">Inspect dataset</a>
    <a class='right-next' id="next-link" href="predict.html" title="next page">Predict</a>

    </div>
    <footer class="footer mt-5 mt-md-0">
    <div class="container">
      <p>
        
          By ncb lab<br/>
        
            &copy; Copyright 2020.<br/>
      </p>
    </div>
  </footer>
</main>


      </div>
    </div>

    
  <script src="../_static/js/index.3da636dd464baa7582d2.js"></script>


    
  </body>
</html>