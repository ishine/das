
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Training</title>
    
  <link rel="stylesheet" href="../_static/css/index.73d71520a4ca3b99cfee5594769eaaae.css">

    
  <link rel="stylesheet"
    href="../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      
  <link rel="stylesheet"
    href="../_static/vendor/open-sans_all/1.44.1/index.css">
  <link rel="stylesheet"
    href="../_static/vendor/lato_latin-ext/1.44.1/index.css">

    
    <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
    <link rel="stylesheet" href="../_static/sphinx-book-theme.40e2e510f6b7d1648584402491bb10fe.css" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-main.c949a650a448cc0ae9fd3441c0e17fb0.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-variables.06eb56fa6e07937060861dad626602ad.css" />
    
  <link rel="preload" as="script" href="../_static/js/index.3da636dd464baa7582d2.js">

    <script id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/language_data.js"></script>
    <script src="../_static/togglebutton.js"></script>
    <script src="../_static/clipboard.min.js"></script>
    <script src="../_static/copybutton.js"></script>
    <script >var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="../_static/sphinx-book-theme.d31b09fe5c1d09cb49b26a786de4a05d.js"></script>
    <script async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <script type="text/x-mathjax-config">MathJax.Hub.Config({"tex2jax": {"inlineMath": [["\\(", "\\)"]], "displayMath": [["\\[", "\\]"]], "processRefs": false, "processEnvironments": false}})</script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script src="https://unpkg.com/@jupyter-widgets/html-manager@^0.18.0/dist/embed-amd.js"></script>
    <script async="async" src="https://unpkg.com/thebelab@latest/lib/index.js"></script>
    <script >
        const thebe_selector = ".thebe"
        const thebe_selector_input = "pre"
        const thebe_selector_output = ".output"
    </script>
    <script async="async" src="../_static/sphinx-thebe.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Predict" href="predict.html" />
    <link rel="prev" title="Make datasets with custom data" href="make_ds_notebook.html" />

    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="en" />



  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    

    <div class="container-xl">
      <div class="row">
          
<div class="col-12 col-md-3 bd-sidebar site-navigation show" id="site-navigation">
    
        <div class="navbar-brand-box">
<a class="navbar-brand text-wrap" href="../index.html">
  
  <img src="../_static/icon.png" class="logo" alt="logo">
  
  
</a>
</div><form class="bd-search d-flex align-items-center" action="../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form>
<nav class="bd-links" id="bd-docs-nav" aria-label="Main navigation">
    <ul class="nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="../intro.html">
   Welcome to DeepSS
  </a>
 </li>
</ul>
<ul class="current nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="../install.html">
   Install
  </a>
 </li>
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="../tutorials_gui/tutorials_gui.html">
   GUI tutorial
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="../tutorials_gui/annotate.html">
     Annotate song
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../tutorials_gui/train.html">
     Train
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../tutorials_gui/predict.html">
     Predict
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
 <li class="toctree-l1 current active collapsible-parent">
  <a class="reference internal" href="tutorials.html">
   Programming tutorial
  </a>
  <ul class="current collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="convert.html">
     Convert your own annotations and audio data
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="make_ds_notebook.html">
     Make datasets with custom data
    </a>
   </li>
   <li class="toctree-l2 current active">
    <a class="current reference internal" href="#">
     Training
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="predict.html">
     Predict
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="evaluate_fly.html">
     Evaluate for fly sine and pulse song
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="evaluate_bird.html">
     Evaluate for bird song
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="realtime.html">
     Realtime annotations
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="../unsupervised/unsupervised.html">
   Unsupervised classification
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="../unsupervised/flies.html">
     Courtship song of flies
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../unsupervised/mice.html">
     Ultrasonic vocalizations from mice
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../unsupervised/birds.html">
     Song of Bengalese finches
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="../technical/technical.html">
   Technical details
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="../technical/data_formats.html">
     Data formats
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../technical/cli.html">
     Command line interfaces
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
</ul>

</nav> <!-- To handle the deprecated key -->

<div class="navbar_extra_footer">
  Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
</div>

</div>


          


          
<main class="col py-md-3 pl-md-4 bd-content overflow-auto" role="main">
    
    <div class="row topbar fixed-top container-xl">
    <div class="col-12 col-md-3 bd-topbar-whitespace site-navigation show">
    </div>
    <div class="col pl-2 topbar-main">
        
        <button id="navbar-toggler" class="navbar-toggler ml-0" type="button" data-toggle="collapse"
            data-toggle="tooltip" data-placement="bottom" data-target=".site-navigation" aria-controls="navbar-menu"
            aria-expanded="true" aria-label="Toggle navigation" aria-controls="site-navigation"
            title="Toggle navigation" data-toggle="tooltip" data-placement="left">
            <i class="fas fa-bars"></i>
            <i class="fas fa-arrow-left"></i>
            <i class="fas fa-arrow-up"></i>
        </button>
        
        
<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn" aria-label="Download this page"><i
            class="fas fa-download"></i></button>

    <div class="dropdown-buttons">
        <!-- ipynb file if we had a myst markdown file -->
        
        <!-- Download raw file -->
        <a class="dropdown-buttons" href="../_sources/tutorials/train.ipynb"><button type="button"
                class="btn btn-secondary topbarbtn" title="Download source file" data-toggle="tooltip"
                data-placement="left">.ipynb</button></a>
        <!-- Download PDF via print -->
        <button type="button" id="download-print" class="btn btn-secondary topbarbtn" title="Print to PDF"
            onClick="window.print()" data-toggle="tooltip" data-placement="left">.pdf</button>
    </div>
</div>

        <!-- Source interaction buttons -->


        <!-- Full screen (wrap in <a> to have style consistency -->
        <a class="full-screen-button"><button type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip"
                data-placement="bottom" onclick="toggleFullScreen()" aria-label="Fullscreen mode"
                title="Fullscreen mode"><i
                    class="fas fa-expand"></i></button></a>

        <!-- Launch buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Launch interactive content"><i class="fas fa-rocket"></i></button>
    <div class="dropdown-buttons">
        
        <a class="binder-button" href="https://mybinder.org/v2/gh/executablebooks/jupyter-book/master?urlpath=tree/tutorials/train.ipynb"><button type="button"
                class="btn btn-secondary topbarbtn" title="Launch Binder" data-toggle="tooltip"
                data-placement="left"><img class="binder-button-logo"
                    src="../_static/images/logo_binder.svg"
                    alt="Interact on binder">Binder</button></a>
        
        
        
        
    </div>
</div>

    </div>

    <!-- Table of contents -->
    <div class="d-none d-md-block col-md-2 bd-toc show">
        
        <div class="tocsection onthispage pt-5 pb-3">
            <i class="fas fa-list"></i> Contents
        </div>
        <nav id="bd-toc-nav">
            <ul class="nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#training-using-python">
   Training using python
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#training-using-command-line-scripts">
   Training using command-line scripts
  </a>
 </li>
</ul>

        </nav>
        
    </div>
</div>
    <div id="main-content" class="row">
        <div class="col-12 col-md-9 pl-md-3 pr-md-0">
        
              <div>
                
  <div class="section" id="training">
<h1>Training<a class="headerlink" href="#training" title="Permalink to this headline">¶</a></h1>
<p>The network can be trained using three interfaces:</p>
<ul class="simple">
<li><p>python, via <code class="docutils literal notranslate"><span class="pre">dss.train.train</span></code></p></li>
<li><p>the command-line interface <code class="docutils literal notranslate"><span class="pre">dss-train</span></code>.</p></li>
<li><p>the GUI - see the <a class="reference internal" href="../tutorials_gui/train.html"><span class="doc std std-doc">GUI tutorial</span></a></p></li>
</ul>
<p>Training will:</p>
<ul class="simple">
<li><p>load train/val/test data form a dataset</p></li>
<li><p>initialize the network</p></li>
<li><p>save all parameters for reproducibility</p></li>
<li><p>train the network and save the best network to disk</p></li>
<li><p>run inference and evaluate the network using the test data.</p></li>
</ul>
<p>The names of files created during training start with an optional prefix and the time stamp of the start time of training, as in <code class="docutils literal notranslate"><span class="pre">my-awesome-prefix_20192310_091032</span></code>. Typically, three files are created:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">*_params.yaml</span></code> - training parameters etc.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">*_model.h5</span></code> -  model architecture and weights</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">*_results.h5</span></code> - predictions and evaluation results for the test set (only created if the training dataset contains a test set)</p></li>
</ul>
<div class="section" id="training-using-python">
<h2>Training using python<a class="headerlink" href="#training-using-python" title="Permalink to this headline">¶</a></h2>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">dss.train</span>
<span class="n">help</span><span class="p">(</span><span class="n">dss</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">train</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Help on function train in module dss.train:

train(*, data_dir: str, y_suffix: str = &#39;&#39;, save_dir: str = &#39;./&#39;, save_prefix: str = None, model_name: str = &#39;tcn&#39;, nb_filters: int = 16, kernel_size: int = 16, nb_conv: int = 3, use_separable: List[bool] = False, nb_hist: int = 1024, ignore_boundaries: bool = True, batch_norm: bool = True, nb_pre_conv: int = 0, pre_kernel_size: int = 3, pre_nb_filters: int = 16, pre_nb_conv: int = 2, verbose: int = 2, batch_size: int = 32, nb_epoch: int = 400, learning_rate: float = None, reduce_lr: bool = False, reduce_lr_patience: int = 5, fraction_data: float = None, seed: int = None, batch_level_subsampling: bool = False, tensorboard: bool = False, log_messages: bool = False, nb_stacks: int = 2, with_y_hist: bool = True, x_suffix: str = &#39;&#39;)
    Train a DeepSS network.
    
    Args:
        data_dir (str): Path to the directory or file with the dataset for training.
                        Accepts npy-dirs (recommended), h5 files or zarr files.
                        See documentation for how the dataset should be organized.
        y_suffix (str): Select training target by suffix.
                        Song-type specific targets can be created with a training dataset,
                        Defaults to &#39;&#39; (will use the standard target &#39;y&#39;)
        save_dir (str): Directory to save training outputs.
                        The path of output files will constructed from the SAVE_DIR, an optional prefix, and the time stamp of the start of training.
                        Defaults to current directory (&#39;./&#39;).
        save_prefix (str): Prepend to timestamp.
                           Name of files created will be SAVE_DIR/SAVE_PREFIX + &quot;_&quot; + TIMESTAMP
                           or SAVE_DIR/ TIMESTAMP if SAVE_PREFIX is empty.
                           Defaults to &#39;&#39; (empty).
        model_name (str): Network architecture to use.
                          Use &quot;tcn&quot; (TCN) or &quot;tcn_stft&quot; (TCN with STFT frontend).
                          See dss.models for a description of all models.
                          Defaults to &#39;tcn&#39;.
        nb_filters (int): Number of filters per layer.
                          Defaults to 16.
        kernel_size (int): Duration of the filters (=kernels) in samples.
                           Defaults to 16.
        nb_conv (int): Number of TCN blocks in the network.
                       Defaults to 3.
        use_separable (List[bool]): Specify which TCN blocks should use separable convolutions.
                                    Provide as a space-separated sequence of &quot;False&quot; or &quot;True.
                                    For instance: &quot;True False False&quot; will set the first block in a
                                    three-block (as given by nb_conv) network to use separable convolutions.
                                    Defaults to False (no block uses separable convolution).
        nb_hist (int): Number of samples processed at once by the network (a.k.a chunk size).
                       Defaults to 1024.
        ignore_boundaries (bool): Minimize edge effects by discarding predictions at the edges of chunks.
                                  Defaults to True.
        batch_norm (bool): Batch normalize.
                           Defaults to True.
        nb_pre_conv (int): Adds downsampling frontend.
                           TCN: adds a frontend of N conv blocks (conv-relu-batchnorm-maxpool2) to the TCN - useful for reducing the sampling rate for USV.
                           TCN_STFT: stft
                           Defaults to 0 (no frontend).
        pre_nb_filters (int): [description]. Defaults to 16.
        pre_kernel_size (int): [description]. Defaults to 3.
        pre_nb_conv (int): [description]. Defaults to 3.
        verbose (int): Verbosity of training output (0 - no output(?), 1 - progress bar, 2 - one line per epoch).
                       Defaults to 2.
        batch_size (int): Batch size
                          Defaults to 32.
        nb_epoch (int): Maximal number of training epochs.
                        Training will stop early if validation loss did not decrease in the last 20 epochs.
                        Defaults to 400.
        learning_rate (float): Learning rate of the model. Defaults should work in most cases.
                               Values typically range between 0.1 and 0.00001.
                               If None, uses per model defaults: &quot;tcn&quot; 0.0001, &quot;tcn_stft&quot; 0.0005).
                               Defaults to None.
        reduce_lr (bool): Reduce learning rate on plateau.
                          Defaults to False.
        reduce_lr_patience (int): Number of epochs w/o a reduction in validation loss after which to trigger a reduction in learning rate.
                                  Defaults to 5.
        fraction_data (float): Fraction of training and validation to use for training.
                               Defaults to 1.0.
        seed (int): Random seed to reproducible select fractions of the data.
                    Defaults to None (no seed).
        batch_level_subsampling (bool): Select fraction of data for training from random subset of shuffled batches.
                                        If False, select a continuous chunk of the recording.
                                        Defaults to False.
        tensorboard (bool): Write tensorboard logs to save_dir.
                            Defaults to False.
        log_messages (bool): Sets logging level to INFO.
                             Defaults to False (will follow existing settings).
        nb_stacks (int): Unused if model name is &quot;tcn&quot; or &quot;tcn_stft&quot;. Defaults to 2.
        with_y_hist (bool): Unused if model name is &quot;tcn&quot; or &quot;tcn_stft&quot;. Defaults to True.
        x_suffix (str): Select specific training data based on suffix (e.g. x_suffix).
                        Defaults to &#39;&#39; (will use the standard data &#39;x&#39;)
</pre></div>
</div>
</div>
</div>
<div class="cell tag_outputPrepend docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">dss</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">train</span><span class="p">(</span><span class="n">model_name</span><span class="o">=</span><span class="s1">&#39;tcn&#39;</span><span class="p">,</span>  <span class="c1"># see `dss.models` for valid model_names</span>
                <span class="n">data_dir</span><span class="o">=</span><span class="s1">&#39;dat/dmel_single_raw.npy&#39;</span><span class="p">,</span> 
                <span class="n">save_dir</span><span class="o">=</span><span class="s1">&#39;res&#39;</span><span class="p">,</span>
                <span class="n">nb_hist</span><span class="o">=</span><span class="mi">512</span><span class="p">,</span>
                <span class="n">kernel_size</span><span class="o">=</span><span class="mi">16</span><span class="p">,</span>
                <span class="n">nb_filters</span><span class="o">=</span><span class="mi">16</span><span class="p">,</span>
                <span class="n">ignore_boundaries</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                <span class="n">verbose</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
                <span class="n">nb_epoch</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
                <span class="n">log_messages</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output traceback highlight-ipythontb notranslate"><div class="highlight"><pre><span></span><span class="gt">---------------------------------------------------------------------------</span>
<span class="ne">KeyboardInterrupt</span><span class="g g-Whitespace">                         </span>Traceback (most recent call last)
<span class="o">&lt;</span><span class="n">ipython</span><span class="o">-</span><span class="nb">input</span><span class="o">-</span><span class="mi">3</span><span class="o">-</span><span class="mi">3249</span><span class="n">b10762bd</span><span class="o">&gt;</span> <span class="ow">in</span> <span class="o">&lt;</span><span class="n">module</span><span class="o">&gt;</span>
<span class="g g-Whitespace">      </span><span class="mi">8</span>                 <span class="n">verbose</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
<span class="g g-Whitespace">      </span><span class="mi">9</span>                 <span class="n">nb_epoch</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
<span class="ne">---&gt; </span><span class="mi">10</span>                 <span class="n">log_messages</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="nn">/Volumes/shinkansen/Dropbox/code.py/deepss/src/dss/train.py</span> in <span class="ni">train</span><span class="nt">(data_dir, y_suffix, save_dir, save_prefix, model_name, nb_filters, kernel_size, nb_conv, use_separable, nb_hist, ignore_boundaries, batch_norm, nb_pre_conv, pre_kernel_size, pre_nb_filters, pre_nb_conv, verbose, batch_size, nb_epoch, learning_rate, reduce_lr, reduce_lr_patience, fraction_data, seed, batch_level_subsampling, tensorboard, log_messages, nb_stacks, with_y_hist, x_suffix)</span>
<span class="g g-Whitespace">    </span><span class="mi">228</span>         <span class="n">verbose</span><span class="o">=</span><span class="n">verbose</span><span class="p">,</span>
<span class="g g-Whitespace">    </span><span class="mi">229</span>         <span class="n">validation_data</span><span class="o">=</span><span class="n">val_gen</span><span class="p">,</span>
<span class="ne">--&gt; </span><span class="mi">230</span>         <span class="n">callbacks</span><span class="o">=</span><span class="n">callbacks</span><span class="p">,</span>
<span class="g g-Whitespace">    </span><span class="mi">231</span>     <span class="p">)</span>
<span class="g g-Whitespace">    </span><span class="mi">232</span> 

<span class="nn">~/miniconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training.py</span> in <span class="ni">fit</span><span class="nt">(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)</span>
<span class="g g-Whitespace">    </span><span class="mi">726</span>         <span class="n">max_queue_size</span><span class="o">=</span><span class="n">max_queue_size</span><span class="p">,</span>
<span class="g g-Whitespace">    </span><span class="mi">727</span>         <span class="n">workers</span><span class="o">=</span><span class="n">workers</span><span class="p">,</span>
<span class="ne">--&gt; </span><span class="mi">728</span>         <span class="n">use_multiprocessing</span><span class="o">=</span><span class="n">use_multiprocessing</span><span class="p">)</span>
<span class="g g-Whitespace">    </span><span class="mi">729</span> 
<span class="g g-Whitespace">    </span><span class="mi">730</span>   <span class="k">def</span> <span class="nf">evaluate</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span>

<span class="nn">~/miniconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_generator.py</span> in <span class="ni">fit</span><span class="nt">(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing)</span>
<span class="g g-Whitespace">    </span><span class="mi">601</span>         <span class="n">shuffle</span><span class="o">=</span><span class="n">shuffle</span><span class="p">,</span>
<span class="g g-Whitespace">    </span><span class="mi">602</span>         <span class="n">initial_epoch</span><span class="o">=</span><span class="n">initial_epoch</span><span class="p">,</span>
<span class="ne">--&gt; </span><span class="mi">603</span>         <span class="n">steps_name</span><span class="o">=</span><span class="s1">&#39;steps_per_epoch&#39;</span><span class="p">)</span>
<span class="g g-Whitespace">    </span><span class="mi">604</span> 
<span class="g g-Whitespace">    </span><span class="mi">605</span>   <span class="k">def</span> <span class="nf">evaluate</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span>

<span class="nn">~/miniconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_generator.py</span> in <span class="ni">model_iteration</span><span class="nt">(model, data, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch, mode, batch_size, steps_name, **kwargs)</span>
<span class="g g-Whitespace">    </span><span class="mi">263</span> 
<span class="g g-Whitespace">    </span><span class="mi">264</span>       <span class="n">is_deferred</span> <span class="o">=</span> <span class="ow">not</span> <span class="n">model</span><span class="o">.</span><span class="n">_is_compiled</span>
<span class="ne">--&gt; </span><span class="mi">265</span>       <span class="n">batch_outs</span> <span class="o">=</span> <span class="n">batch_function</span><span class="p">(</span><span class="o">*</span><span class="n">batch_data</span><span class="p">)</span>
<span class="g g-Whitespace">    </span><span class="mi">266</span>       <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">batch_outs</span><span class="p">,</span> <span class="nb">list</span><span class="p">):</span>
<span class="g g-Whitespace">    </span><span class="mi">267</span>         <span class="n">batch_outs</span> <span class="o">=</span> <span class="p">[</span><span class="n">batch_outs</span><span class="p">]</span>

<span class="nn">~/miniconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training.py</span> in <span class="ni">train_on_batch</span><span class="nt">(self, x, y, sample_weight, class_weight, reset_metrics)</span>
<span class="g g-Whitespace">   </span><span class="mi">1016</span>       <span class="bp">self</span><span class="o">.</span><span class="n">_update_sample_weight_modes</span><span class="p">(</span><span class="n">sample_weights</span><span class="o">=</span><span class="n">sample_weights</span><span class="p">)</span>
<span class="g g-Whitespace">   </span><span class="mi">1017</span>       <span class="bp">self</span><span class="o">.</span><span class="n">_make_train_function</span><span class="p">()</span>
<span class="ne">-&gt; </span><span class="mi">1018</span>       <span class="n">outputs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">train_function</span><span class="p">(</span><span class="n">ins</span><span class="p">)</span>  <span class="c1"># pylint: disable=not-callable</span>
<span class="g g-Whitespace">   </span><span class="mi">1019</span> 
<span class="g g-Whitespace">   </span><span class="mi">1020</span>     <span class="k">if</span> <span class="n">reset_metrics</span><span class="p">:</span>

<span class="nn">~/miniconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/backend.py</span> in <span class="ni">__call__</span><span class="nt">(self, inputs)</span>
<span class="g g-Whitespace">   </span><span class="mi">3578</span> 
<span class="g g-Whitespace">   </span><span class="mi">3579</span>     <span class="n">fetched</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_callable_fn</span><span class="p">(</span><span class="o">*</span><span class="n">array_vals</span><span class="p">,</span>
<span class="ne">-&gt; </span><span class="mi">3580</span>                                 <span class="n">run_metadata</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">run_metadata</span><span class="p">)</span>
<span class="g g-Whitespace">   </span><span class="mi">3581</span>     <span class="bp">self</span><span class="o">.</span><span class="n">_call_fetch_callbacks</span><span class="p">(</span><span class="n">fetched</span><span class="p">[</span><span class="o">-</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_fetches</span><span class="p">):])</span>
<span class="g g-Whitespace">   </span><span class="mi">3582</span>     <span class="n">output_structure</span> <span class="o">=</span> <span class="n">nest</span><span class="o">.</span><span class="n">pack_sequence_as</span><span class="p">(</span>

<span class="nn">~/miniconda3/lib/python3.7/site-packages/tensorflow_core/python/client/session.py</span> in <span class="ni">__call__</span><span class="nt">(self, *args, **kwargs)</span>
<span class="g g-Whitespace">   </span><span class="mi">1470</span>         <span class="n">ret</span> <span class="o">=</span> <span class="n">tf_session</span><span class="o">.</span><span class="n">TF_SessionRunCallable</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_session</span><span class="o">.</span><span class="n">_session</span><span class="p">,</span>
<span class="g g-Whitespace">   </span><span class="mi">1471</span>                                                <span class="bp">self</span><span class="o">.</span><span class="n">_handle</span><span class="p">,</span> <span class="n">args</span><span class="p">,</span>
<span class="ne">-&gt; </span><span class="mi">1472</span>                                                <span class="n">run_metadata_ptr</span><span class="p">)</span>
<span class="g g-Whitespace">   </span><span class="mi">1473</span>         <span class="k">if</span> <span class="n">run_metadata</span><span class="p">:</span>
<span class="g g-Whitespace">   </span><span class="mi">1474</span>           <span class="n">proto_data</span> <span class="o">=</span> <span class="n">tf_session</span><span class="o">.</span><span class="n">TF_GetBuffer</span><span class="p">(</span><span class="n">run_metadata_ptr</span><span class="p">)</span>

<span class="ne">KeyboardInterrupt</span>: 
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="training-using-command-line-scripts">
<h2>Training using command-line scripts<a class="headerlink" href="#training-using-command-line-scripts" title="Permalink to this headline">¶</a></h2>
<p>The training function <code class="docutils literal notranslate"><span class="pre">dss.train.train</span></code> and all its arguments are also accessible from the command line via <code class="docutils literal notranslate"><span class="pre">dss-train</span></code> for use on the terminal. See <span class="xref myst">here</span> for a description of all command-line arguments. The command-line interface is generated with <a class="reference external" href="https://defopt.readthedocs.io/en/stable/index.html">defopt</a>.</p>
<p>For instance, training commaned above can be invoked from the command line:</p>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span>python -m dss.train --data-dir dat/dmel_single_raw.npy --save-dir res --model-name tcn --kernel-size <span class="m">16</span> --nb-filters <span class="m">16</span> --nb-hist <span class="m">512</span> --nb-epoch <span class="m">20</span> -i
</pre></div>
</div>
<p>Shell scripts are particularly useful if you want to fit a set of networks with with different configurations to optimize architecture. For instance, this scripts will fit networsk with different numbers of TCN blocks (<code class="docutils literal notranslate"><span class="pre">nb_conv</span></code>) and filters (<code class="docutils literal notranslate"><span class="pre">nb_filters</span></code>):</p>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span><span class="ch">#!/bin/bash</span>
conda activate dss

<span class="nv">YSUFFIX</span><span class="o">=</span><span class="s2">&quot;pulse&quot;</span>
<span class="nv">MODELNAME</span><span class="o">=</span><span class="s1">&#39;tcn&#39;</span>
<span class="nv">DATADIR</span><span class="o">=</span><span class="s1">&#39;../dat/dmel_single.npy&#39;</span>
<span class="nv">SAVEDIR</span><span class="o">=</span><span class="s2">&quot;res&quot;</span>

<span class="nv">NB_HIST</span><span class="o">=</span><span class="m">2048</span>
<span class="nv">KERNEL_SIZE</span><span class="o">=</span><span class="m">32</span>
<span class="nv">NB_FILTERS</span><span class="o">=</span><span class="m">32</span>
<span class="nv">NB_CONV</span><span class="o">=</span><span class="m">3</span>

<span class="k">for</span> NB_CONV in <span class="m">2</span> <span class="m">3</span> <span class="m">4</span>
<span class="k">do</span>
    <span class="k">for</span> NB_FILTERS in <span class="m">16</span> <span class="m">32</span> <span class="m">48</span> <span class="m">64</span>
    <span class="k">do</span>
        python3 -m dss.train -i --nb-filters <span class="nv">$NB_FILTERS</span> --kernel-size <span class="nv">$KERNEL_SIZE</span> --nb-conv <span class="nv">$NB_CONV</span> --nb-hist <span class="nv">$NB_HIST</span> --save-dir <span class="nv">$SAVEDIR</span> --y-suffix <span class="nv">$YSUFFIX</span> --data-dir <span class="nv">$DATADIR</span> --model-name <span class="nv">$MODELNAME</span>
    <span class="k">done</span>
<span class="k">done</span>
</pre></div>
</div>
<p>A description of all command line arguments can be obtained by typing <code class="docutils literal notranslate"><span class="pre">dss-gui</span> <span class="pre">--help</span></code> in a terminal:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">!</span>dss-train --help
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>usage: dss-train [-h] -d DATA_DIR [-y Y_SUFFIX] [--save-dir SAVE_DIR]
                 [--save-prefix SAVE_PREFIX] [-m MODEL_NAME]
                 [--nb-filters NB_FILTERS] [-k KERNEL_SIZE]
                 [--nb-conv NB_CONV] [-u [USE_SEPARABLE [USE_SEPARABLE ...]]]
                 [--nb-hist NB_HIST] [-i] [--no-ignore-boundaries]
                 [--batch-norm] [--no-batch-norm] [--nb-pre-conv NB_PRE_CONV]
                 [--pre-kernel-size PRE_KERNEL_SIZE]
                 [--pre-nb-filters PRE_NB_FILTERS] [--pre-nb-conv PRE_NB_CONV]
                 [-v VERBOSE] [--batch-size BATCH_SIZE] [--nb-epoch NB_EPOCH]
                 [--learning-rate LEARNING_RATE] [--reduce-lr]
                 [--no-reduce-lr] [--reduce-lr-patience REDUCE_LR_PATIENCE]
                 [-f FRACTION_DATA] [--seed SEED] [--batch-level-subsampling]
                 [--no-batch-level-subsampling] [-t] [--no-tensorboard]
                 [--log-messages] [--no-log-messages] [--nb-stacks NB_STACKS]
                 [-w] [--no-with-y-hist] [-x X_SUFFIX] [--version]

Train a DeepSS network.

optional arguments:
  -h, --help            show this help message and exit
  -d DATA_DIR, --data-dir DATA_DIR
                        Path to the directory or file with the dataset for training.
                        Accepts npy-dirs (recommended), h5 files or zarr files.
                        See documentation for how the dataset should be organized.
  -y Y_SUFFIX, --y-suffix Y_SUFFIX
                        Select training target by suffix.
                        Song-type specific targets can be created with a training dataset,
                        Defaults to &#39;&#39; (will use the standard target &#39;y&#39;)
                        (default: )
  --save-dir SAVE_DIR   Directory to save training outputs.
                        The path of output files will constructed from the SAVE_DIR, an optional prefix, and the time stamp of the start of training.
                        Defaults to current directory (&#39;./&#39;).
                        (default: ./)
  --save-prefix SAVE_PREFIX
                        Prepend to timestamp.
                        Name of files created will be SAVE_DIR/SAVE_PREFIX + &quot;_&quot; + TIMESTAMP
                        or SAVE_DIR/ TIMESTAMP if SAVE_PREFIX is empty.
                        Defaults to &#39;&#39; (empty).
                        (default: None)
  -m MODEL_NAME, --model-name MODEL_NAME
                        Network architecture to use.
                        Use &quot;tcn&quot; (TCN) or &quot;tcn_stft&quot; (TCN with STFT frontend).
                        See dss.models for a description of all models.
                        Defaults to &#39;tcn&#39;.
                        (default: tcn)
  --nb-filters NB_FILTERS
                        Number of filters per layer.
                        Defaults to 16.
                        (default: 16)
  -k KERNEL_SIZE, --kernel-size KERNEL_SIZE
                        Duration of the filters (=kernels) in samples.
                        Defaults to 16.
                        (default: 16)
  --nb-conv NB_CONV     Number of TCN blocks in the network.
                        Defaults to 3.
                        (default: 3)
  -u [USE_SEPARABLE [USE_SEPARABLE ...]], --use-separable [USE_SEPARABLE [USE_SEPARABLE ...]]
                        Specify which TCN blocks should use separable convolutions.
                        Provide as a space-separated sequence of &quot;False&quot; or &quot;True.
                        For instance: &quot;True False False&quot; will set the first block in a
                        three-block (as given by nb_conv) network to use separable convolutions.
                        Defaults to False (no block uses separable convolution).
                        (default: False)
  --nb-hist NB_HIST     Number of samples processed at once by the network (a.k.a chunk size).
                        Defaults to 1024.
                        (default: 1024)
  -i, --ignore-boundaries
                        Minimize edge effects by discarding predictions at the edges of chunks.
                        Defaults to True.
                        (default: True)
  --no-ignore-boundaries
  --batch-norm          Batch normalize.
                        Defaults to True.
                        (default: True)
  --no-batch-norm
  --nb-pre-conv NB_PRE_CONV
                        Adds downsampling frontend.
                        TCN: adds a frontend of N conv blocks (conv-relu-batchnorm-maxpool2) to the TCN - useful for reducing the sampling rate for USV.
                        TCN_STFT: stft
                        Defaults to 0 (no frontend).
                        (default: 0)
  --pre-kernel-size PRE_KERNEL_SIZE
                        [description]. Defaults to 3.
                        (default: 3)
  --pre-nb-filters PRE_NB_FILTERS
                        [description]. Defaults to 16.
                        (default: 16)
  --pre-nb-conv PRE_NB_CONV
                        [description]. Defaults to 3.
                        (default: 2)
  -v VERBOSE, --verbose VERBOSE
                        Verbosity of training output (0 - no output(?), 1 - progress bar, 2 - one line per epoch).
                        Defaults to 2.
                        (default: 2)
  --batch-size BATCH_SIZE
                        Batch size
                        Defaults to 32.
                        (default: 32)
  --nb-epoch NB_EPOCH   Maximal number of training epochs.
                        Training will stop early if validation loss did not decrease in the last 20 epochs.
                        Defaults to 400.
                        (default: 400)
  --learning-rate LEARNING_RATE
                        Learning rate of the model. Defaults should work in most cases.
                        Values typically range between 0.1 and 0.00001.
                        If None, uses per model defaults: &quot;tcn&quot; 0.0001, &quot;tcn_stft&quot; 0.0005).
                        Defaults to None.
                        (default: None)
  --reduce-lr           Reduce learning rate on plateau.
                        Defaults to False.
                        (default: False)
  --no-reduce-lr
  --reduce-lr-patience REDUCE_LR_PATIENCE
                        Number of epochs w/o a reduction in validation loss after which to trigger a reduction in learning rate.
                        Defaults to 5.
                        (default: 5)
  -f FRACTION_DATA, --fraction-data FRACTION_DATA
                        Fraction of training and validation to use for training.
                        Defaults to 1.0.
                        (default: None)
  --seed SEED           Random seed to reproducible select fractions of the data.
                        Defaults to None (no seed).
                        (default: None)
  --batch-level-subsampling
                        Select fraction of data for training from random subset of shuffled batches.
                        If False, select a continuous chunk of the recording.
                        Defaults to False.
                        (default: False)
  --no-batch-level-subsampling
  -t, --tensorboard     Write tensorboard logs to save_dir.
                        Defaults to False.
                        (default: False)
  --no-tensorboard
  --log-messages        Sets logging level to INFO.
                        Defaults to False (will follow existing settings).
                        (default: False)
  --no-log-messages
  --nb-stacks NB_STACKS
                        Unused if model name is &quot;tcn&quot; or &quot;tcn_stft&quot;. Defaults to 2.
                        (default: 2)
  -w, --with-y-hist     Unused if model name is &quot;tcn&quot; or &quot;tcn_stft&quot;. Defaults to True.
                        (default: True)
  --no-with-y-hist
  -x X_SUFFIX, --x-suffix X_SUFFIX
                        Select specific training data based on suffix (e.g. x_suffix).
                        Defaults to &#39;&#39; (will use the standard data &#39;x&#39;)
                        (default: )
  --version             show program&#39;s version number and exit

</pre></div>
</div>
</div>
</div>
</div>
</div>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./tutorials"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
        </div>
    </div>
    
    
    <div class='prev-next-bottom'>
        
    <a class='left-prev' id="prev-link" href="make_ds_notebook.html" title="previous page">Make datasets with custom data</a>
    <a class='right-next' id="next-link" href="predict.html" title="next page">Predict</a>

    </div>
    <footer class="footer mt-5 mt-md-0">
    <div class="container">
      <p>
        
          By ncb lab<br/>
        
            &copy; Copyright 2020.<br/>
      </p>
    </div>
  </footer>
</main>


      </div>
    </div>

    
  <script src="../_static/js/index.3da636dd464baa7582d2.js"></script>


    
  </body>
</html>