{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict\n",
    "Similar to training, prediction can be done via three interfaces:\n",
    "- via python, `dss.predict.predict`\n",
    "- via the command line, `dss predict`, with audio data from a wav file.\n",
    "- the GUI - see the [GUI tutorial](/tutorials_gui/predict)\n",
    "\n",
    "Prediction will:\n",
    "\n",
    "- load the audio data and the network\n",
    "- run inference to produce confidence scores (`class_probabilties`)\n",
    "- post-process the confidence score to extract the times of events and label segments.\n"
   ]
  },
  {
   "source": [
    "## Prediction using python"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Help on function predict in module dss.predict:\n\npredict(x: <built-in function array>, model_save_name: str = None, verbose: int = 1, batch_size: int = None, model: tensorflow.python.keras.engine.training.Model = None, params: dict = None, event_thres: float = 0.5, event_dist: float = 0.01, event_dist_min: float = 0, event_dist_max: float = None, segment_thres: float = 0.5, segment_minlen: float = None, segment_fillgap: float = None, prepend_padding: bool = True)\n    [summary]\n    \n    Usage:\n    Calling predict with the path to the model will load the model and the\n    associated params and run inference:\n    `dss.predict.predict(x=data, model_save_name='tata')`\n    \n    To re-use the same model with multiple recordings, load the modal and params\n    once and pass them to `predict`\n    ```my_model, my_params = dss.utils.load_model_and_params(model_save_name)\n    for data in data_list:\n        dss.predict.predict(x=data, model=my_model, params=my_params)\n    ```\n    \n    Args:\n        x (np.array): Audio data [samples, channels]\n        model_save_name (str): path with the trunk name of the model. Defaults to None.\n        model (keras.model.Models): Defaults to None.\n        params (dict): Defaults to None.\n    \n        verbose (int): display progress bar during prediction. Defaults to 1.\n        batch_size (int): number of chunks processed at once . Defaults to None (the default used during training).\n                         Larger batches lead to faster inference. Limited by memory size, in particular for GPUs which typically have 8GB.\n                         Large batch sizes lead to loss of samples since only complete batches are used.\n    \n        event_thres (float): Confidence threshold for detecting peaks. Range 0..1. Defaults to 0.5.\n        event_dist (float): Minimal distance between adjacent events during thresholding.\n                            Prevents detecting duplicate events when the confidence trace is a little noisy.\n                            Defaults to 0.01.\n        event_dist_min (float): MINimal inter-event interval for the event filter run during post processing.\n                                Defaults to 0.\n        event_dist_max (float): MAXimal inter-event interval for the event filter run during post processing.\n                                Defaults to None (no upper limit).\n    \n        segment_thres (float): Confidence threshold for detecting segments. Range 0..1. Defaults to 0.5.\n        segment_minlen (float): Minimal duration of a segment used for filtering out spurious detections. Defaults to None.\n        segment_fillgap (float): Gap between adjacent segments to be filled. Useful for correcting brief lapses. Defaults to None.\n    \n    \n    Raises:\n        ValueError: [description]\n    \n    Returns:\n        events: [description]\n        segments: [description]\n        class_probabilities: [description]\n\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from pprint import pprint\n",
    "import scipy.io.wavfile\n",
    "import dss.predict\n",
    "help(dss.predict.predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "DeepSS requires [T, channels], but single-channel wave files are loaded with shape [T,] (data shape is (909003,)).\n",
      "WARNING:tensorflow:From /Users/clemens10/miniconda3/lib/python3.7/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1635: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "443/443 - 20s\n",
      "CPU times: user 1min 36s, sys: 5.24 s, total: 1min 41s\n",
      "Wall time: 24.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "samplerate, x = scipy.io.wavfile.read('dat/dmel_song_rt.wav')\n",
    "print(f\"DeepSS requires [T, channels], but single-channel wave files are loaded with shape [T,] (data shape is {x.shape}).\")\n",
    "x = np.atleast_2d(x).T\n",
    "events, segments, class_probabilties = dss.predict.predict(x, \n",
    "                                                           model_save_name='models/dmel_single_rt/20200430_201821',\n",
    "                                                           verbose=2)"
   ]
  },
  {
   "source": [
    "### Outputs of `predict`\n",
    "- `class_probabilties`: `[T, nb_classes]` including noise.\n",
    "- `segments`: Labelled segments\n",
    "    - `samplerate_Hz`: \n",
    "    - `names`: names of all segment types\n",
    "    - `index`: indices of all segments types into class_probabiltiies\n",
    "    - `probabilities = class_probabilites[:, index]`\n",
    "    - `sequence`: sequence of segment names (one entry per detected segment). Excludes noise\n",
    "    - `samples`: labelled sample trace (label of the sequence occupying each sample)\n",
    "    - `onsets_seconds`, `offsets_seconds`, `durations_seconds`: Onsets, offsets, and duration of individual segmeents\n",
    "- `events`: Detected events\n",
    "    - `samplerate_Hz`: \n",
    "    - `index`: indices of all events types into class_probabiltiies\n",
    "    - `names`: names of all event types\n",
    "    - `probabilities`: probabilities (confidence scores) for detected events. Value of `class_probabilities` for the detected event index at each event time.\n",
    "    - `seconds`: times (seconds) of detected events\n",
    "    - `sequence`: sequence of event names (one per detected event)."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Prediction using command-line scripts\n",
    "Will save the output to a h5 file ending in `_dss.h5` or specified via the `--save-filename` argument.\n",
    "\n",
    "See [cli](/technical/cli) for a full list of arguments."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "INFO:root:   Loading data from dat/dmel_song_rt.wav.\n",
      "INFO:root:   Annotating using model at models/dmel_single_rt/20200430_201821.\n",
      "WARNING:tensorflow:From /Users/clemens10/miniconda3/lib/python3.7/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1635: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "WARNING:tensorflow:From /Users/clemens10/miniconda3/lib/python3.7/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1635: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "443/443 [==============================] - 20s 45ms/step\n",
      "INFO:root:   Saving results to dat/dmel_song_rt_dss.h5.\n",
      "INFO:root:Done.\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!dss predict dat/dmel_song_rt.wav models/dmel_single_rt/20200430_201821"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "['class_probabilities', 'events', 'segments']\n"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "\n",
    "with h5py.File('dat/dmel_song_rt_dss.h5', mode='r') as f:\n",
    "    print(list(f.keys()))"
   ]
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6-final"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 4
}